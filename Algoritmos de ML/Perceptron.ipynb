{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from scipy.stats import uniform, randint\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '__file__' in locals():\n",
    "    current_folder = os.path.dirname(os.path.abspath(__file__))\n",
    "else:\n",
    "    current_folder = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_features = '\"{}\"'.format(os.path.join(current_folder, '..', 'Features', 'Merge features.ipynb'))\n",
    "calcular_auc = '\"{}\"'.format(os.path.join(current_folder, '..', 'Calcular AUC.ipynb'))\n",
    "set_de_entrenamiento_testing_y_prediccion = '\"{}\"'.format(os.path.join(\n",
    "    current_folder,\n",
    "    '..',\n",
    "    'Set de entrenamiento, testing y predicción.ipynb'\n",
    "))\n",
    "hiperparametros_csv = os.path.join(current_folder, 'hiperparametros', 'perceptron.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.72943, 3.91018]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "La limpieza ya corrió en este Kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/DATOS/UBA/Organizacion de Datos/tp2/Features/../Limpieza.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'limpieza_runned'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'La limpieza ya corrió en este Kernel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlimpieza_runned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: La limpieza ya corrió en este Kernel"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "La limpieza ya corrió en este Kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/DATOS/UBA/Organizacion de Datos/tp2/Features/../Limpieza.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'limpieza_runned'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'La limpieza ya corrió en este Kernel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlimpieza_runned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: La limpieza ya corrió en este Kernel"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "La limpieza ya corrió en este Kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/DATOS/UBA/Organizacion de Datos/tp2/Features/../Limpieza.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'limpieza_runned'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'La limpieza ya corrió en este Kernel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlimpieza_runned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: La limpieza ya corrió en este Kernel"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "%run $merge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(df_features.shape[0] == df['person'].unique().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargo los sets de entrenamiento, testing y predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run $set_de_entrenamiento_testing_y_prediccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento rápido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = labels_training.merge(df_features, how='inner', on='person')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = MLPRegressor()\n",
    "regr.fit(training.drop('label', axis=1), training['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predigo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = labels_test.merge(df_features, how='inner', on='person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test['label_predicted'] = regr.predict(labels_test.drop('label', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc score: 0.43916023233190116\n"
     ]
    }
   ],
   "source": [
    "%run $calcular_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_with_features = labels.merge(df_features, how='inner', on='person')\n",
    "regr = MLPRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    \"hidden_layer_sizes\": [[randint(0, 100).rvs() for i in range(randint(1, 10).rvs())] for i in range(10)],\n",
    "    \"activation\": ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    \"solver\": ['lbfgs', 'adam'],\n",
    "    \"alpha\": uniform(0, 1),\n",
    "    \"learning_rate\": ['constant', 'invscaling', 'adaptive']\n",
    "}\n",
    "\n",
    "splits = 10 # cantidad de splits en el cross validation\n",
    "n_iter_search = 2 # cantidad de combinaciones, en total splits*n_iter_search RF a probar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota: hay más info en la consola desde la cual se corre jupyter.\n",
    "\n",
    "Se puede aumentar *n_jobs* para que corra más procesos en paralelo, pero se corre el riesgo de que se cuelgue por falta de memoria. Recomiendo que prueben ir aumentando *n_jobs* con un *n_iter_search* bajo hasta encontrar el mayor *n_jobs* que se banque su compu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=2)]: Done  20 out of  20 | elapsed: 17.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done  20 out of  20 | elapsed: 17.6min finished\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(regr, param_distributions=param_dist, iid=False, refit=True, verbose=10,\n",
    "                                   return_train_score=True, cv=splits, scoring=make_scorer(roc_auc_score), \n",
    "                                   n_iter=n_iter_search, n_jobs=2);\n",
    "\n",
    "start = time()\n",
    "random_search.fit(labels_with_features.drop('label', axis=1), labels_with_features['label'])\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El **mejor** Perceptron fue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('score: {}'.format(random_search.best_score_))\n",
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado de la búsqueda la podemos importar a un DataFrame de Pandas y analizarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_training = pd.DataFrame(data=random_search.cv_results_)\n",
    "stats_training.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

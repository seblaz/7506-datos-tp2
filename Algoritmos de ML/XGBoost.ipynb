{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "from IPython.display import display\n",
    "from ipywidgets import IntProgress\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '__file__' in locals():\n",
    "    current_folder = os.path.dirname(os.path.abspath(__file__))\n",
    "else:\n",
    "    current_folder = os.getcwd()\n",
    "\n",
    "set_de_entrenamiento_testing_y_prediccion = '\"{}\"'.format(os.path.join(\n",
    "    current_folder,\n",
    "    '..',\n",
    "    'Set de entrenamiento, testing y predicción.ipynb'\n",
    "))\n",
    "merge_features = '\"{}\"'.format(os.path.join(current_folder, '..', 'Features', 'Merge features.ipynb'))\n",
    "calcular_auc = '\"{}\"'.format(os.path.join(current_folder, '..', 'Calcular AUC.ipynb'))\n",
    "predicciones_csv = os.path.join(current_folder, '..', 'predictions.csv')\n",
    "hiperparametros_csv = os.path.join(current_folder, 'hiperparametros', 'xgboost.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargo el df con los features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "La limpieza ya corrió en este Kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/DATOS/UBA/Organizacion de Datos/tp2/Features/../Limpieza.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'limpieza_runned'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'La limpieza ya corrió en este Kernel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlimpieza_runned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: La limpieza ya corrió en este Kernel"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "La limpieza ya corrió en este Kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/DATOS/UBA/Organizacion de Datos/tp2/Features/../Limpieza.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'limpieza_runned'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'La limpieza ya corrió en este Kernel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlimpieza_runned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: La limpieza ya corrió en este Kernel"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "La limpieza ya corrió en este Kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/DATOS/UBA/Organizacion de Datos/tp2/Features/../Limpieza.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'limpieza_runned'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'La limpieza ya corrió en este Kernel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlimpieza_runned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: La limpieza ya corrió en este Kernel"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "%run $merge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(df_features.shape[0] == df['person'].unique().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargo los sets de entrenamiento, testing y predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run $set_de_entrenamiento_testing_y_prediccion\n",
    "\n",
    "labels_with_features = labels.merge(df_features, how='inner', on='person')\n",
    "data = labels_with_features.drop('label', axis=1)\n",
    "target = labels_with_features['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento rápido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con cross validation de xgboost. Lo bueno de esto es que al final me da el *num_boost_round* óptimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'silent': 1,\n",
    "    'objective': 'reg:logistic',\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.1,\n",
    "}\n",
    "cv = 10 # cantidad de splits en el cross validation\n",
    "num_round = 100 # cantidad de veces que se boostea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.3 s, sys: 100 ms, total: 54.4 s\n",
      "Wall time: 13.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dtrain = xgb.DMatrix(data, label=target)\n",
    "result = xgb.cv(param, dtrain, nfold=cv, metrics='auc', verbose_eval=False, shuffle=False, stratified=False, num_boost_round=num_round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El índice + 1 es el *num_boost_round* óptimo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-auc-mean</th>\n",
       "      <th>test-auc-std</th>\n",
       "      <th>train-auc-mean</th>\n",
       "      <th>train-auc-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.87477</td>\n",
       "      <td>0.01197</td>\n",
       "      <td>0.897444</td>\n",
       "      <td>0.001117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test-auc-mean  test-auc-std  train-auc-mean  train-auc-std\n",
       "56        0.87477       0.01197        0.897444       0.001117"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.loc[[result['test-auc-mean'].idxmax()]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Búsqueda de hiperparámetros con Grid Search\n",
    "\n",
    "Vamos a hacer un kfold con sklearn.\n",
    "\n",
    "**Nota**: está busqueda ya no es óptima, es mejor realizarla usando GridSearchCV de sklearn o Bayesian Optimization que está más abajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = 2\n",
    "max_depth_values = 2\n",
    "eta_values = 2\n",
    "gamma_values = 2\n",
    "num_round_values = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'max_depth': 30,\n",
    "    'eta': 0,\n",
    "    'gamma': 0,\n",
    "    'silent': 1,\n",
    "    'objective': 'binary:logistic',\n",
    "    'nthread': 10,\n",
    "    'eval_metric': 'auc'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_auc():\n",
    "    return metrics.roc_auc_score(labels_test['label'], labels_test['label_predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_with_features = labels.merge(df_features, how='inner', on='person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(labels_with_features.columns)\n",
    "columns.remove('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a2087356b44d8a8607d8a9ba68a2c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = IntProgress(min=0, max=splits*max_depth_values*eta_values*gamma_values*num_round_values)\n",
    "display(f) # display the bar\n",
    "\n",
    "kf = KFold(n_splits=splits, shuffle=False)\n",
    "results = pd.DataFrame(columns=['k', 'max_depth', 'eta', 'gamma', 'num_round', 'auc'])\n",
    "index = 0\n",
    "k = 0\n",
    "for train_index, test_index in kf.split(labels):\n",
    "    \n",
    "    labels_training = labels_with_features.iloc[train_index]\n",
    "    labels_test = labels_with_features.iloc[test_index]\n",
    "    assert(labels_training.merge(labels_test, how='inner', on='person').shape[0] == 0)\n",
    "    train_matrix = xgb.DMatrix(labels_training.loc[:, columns], label=labels_training['label'])\n",
    "    test_matrix = xgb.DMatrix(labels_test.loc[:, columns])\n",
    "    \n",
    "    for max_depth, eta, gamma, num_round in np.ndindex((max_depth_values, eta_values, gamma_values, num_round_values)):\n",
    "        eta=eta/eta_values\n",
    "        param['max_depth'] = max_depth\n",
    "        param['eta'] = eta\n",
    "        param['gamma'] = gamma\n",
    "        \n",
    "        bst = xgb.train(param, train_matrix, num_round)\n",
    "        labels_test['label_predicted'] = bst.predict(test_matrix)\n",
    "        \n",
    "        results.loc[index] = k, max_depth, eta, gamma, num_round, calculate_auc()\n",
    "        \n",
    "        index+=1\n",
    "        f.value += 1\n",
    "    \n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Promedio los hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <th>eta</th>\n",
       "      <th>gamma</th>\n",
       "      <th>num_round</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <td>0.776814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    auc\n",
       "max_depth eta gamma num_round          \n",
       "1.0       0.5 0.0   1.0        0.776814"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_mean = results.groupby(['max_depth', 'eta', 'gamma', 'num_round'])[['auc']].mean()\n",
    "mejor_resultado = results_mean.loc[results_mean.idxmax()]\n",
    "mejor_resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escribo los nuevos resultados en un archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = mejor_resultado.reset_index().to_dict('records')[0]\n",
    "auc = params.pop('auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_data = {\n",
    "    'algorithm': 'xgboost',\n",
    "    'hyperparameters': params,\n",
    "    'cv_splits': splits,\n",
    "    'auc': auc,\n",
    "    'features': data.columns\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i write_hyperparameters.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiperparámetros con Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbounds = {\n",
    "    'max_depth': (2, 20),\n",
    "    'eta': (0, 0.3),\n",
    "    'gamma': (0, 10),\n",
    "}\n",
    "\n",
    "discrete = ['max_depth'] # parámetros discretos\n",
    "cv_splits = 10 # cantidad de splits en el cv\n",
    "num_round = 100 # cantidad máxima de boosts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Falta optimizar otros parámetros discretos:\n",
    " - booster \n",
    " - min_child_weight \n",
    " - max_delta_step \n",
    " - etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data, label=target)\n",
    "def cv_score_xgb(**param):\n",
    "    param['silent'] = 1\n",
    "    param['objective'] = 'reg:logistic'\n",
    "    \n",
    "    # transformo los valores que deben ser discretos\n",
    "    for d in discrete:\n",
    "        param[d] = int(param[d])\n",
    "    \n",
    "    # hago el cv\n",
    "    scores = xgb.cv(param, dtrain, nfold=cv_splits, metrics='auc', verbose_eval=False, shuffle=False, stratified=False, num_boost_round=num_round)\n",
    "    return scores['test-auc-mean'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |    eta    |   gamma   | max_depth |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8717  \u001b[0m | \u001b[0m 0.2871  \u001b[0m | \u001b[0m 8.09    \u001b[0m | \u001b[0m 10.7    \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.8647  \u001b[0m | \u001b[0m 0.09968 \u001b[0m | \u001b[0m 0.649   \u001b[0m | \u001b[0m 18.84   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m |\n",
      "=============================================================\n",
      "CPU times: user 8min 31s, sys: 9.23 s, total: 8min 41s\n",
      "Wall time: 2min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "optimizer = BayesianOptimization(f=cv_score_xgb, pbounds=pbounds)\n",
    "optimizer.maximize(\n",
    "    init_points=1,\n",
    "    n_iter=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': {'eta': 0.2870991802700227,\n",
       "  'gamma': 8.090495751293842,\n",
       "  'max_depth': 10.704449460284135},\n",
       " 'target': 0.8717252}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardo el resultado en un archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = optimizer.max['params'].copy()\n",
    "params['max_depth'] = int(params['max_depth'])\n",
    "params['silent'] = 1\n",
    "result = xgb.cv(params, dtrain, nfold=cv_splits, metrics='auc', verbose_eval=False, shuffle=False, stratified=False, num_boost_round=num_round)\n",
    "params['num_round'] = result['test-auc-mean'].idxmax() + 1\n",
    "del params['silent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_data = {\n",
    "    'algorithm': 'xgboost',\n",
    "    'hyperparameters': params,\n",
    "    'cv_splits': cv_splits,\n",
    "    'auc': optimizer.max['target'],\n",
    "    'features': data.columns\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i write_hyperparameters.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predecir labels desconocidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data, label=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'eta': 0.09396,\n",
    "    'gamma': 6.476,\n",
    "    'max_depth': 10,\n",
    "    'silent': 1,\n",
    "    'objective': 'reg:logistic'\n",
    "}\n",
    "num_round = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgb.train(param, dtrain, num_boost_round=num_round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predigo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_predict_with_features = labels_to_predict.merge(df_features, how='inner', on='person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(labels_to_predict.shape[0] == labels_to_predict_with_features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = xgb.DMatrix(labels_to_predict_with_features.loc[:, columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_predict['label'] = bst.predict(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels_to_predict.to_csv(predicciones_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

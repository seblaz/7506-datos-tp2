{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import randint\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '__file__' in locals():\n",
    "    current_folder = os.path.dirname(os.path.abspath(__file__))\n",
    "else:\n",
    "    current_folder = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_features = '\"{}\"'.format(os.path.join(current_folder, '..', 'Features', 'Merge features.ipynb'))\n",
    "calcular_auc = '\"{}\"'.format(os.path.join(current_folder, '..', 'Calcular AUC.ipynb'))\n",
    "set_de_entrenamiento_testing_y_prediccion = '\"{}\"'.format(os.path.join(\n",
    "    current_folder,\n",
    "    '..',\n",
    "    'Set de entrenamiento, testing y predicción.ipynb'\n",
    "))\n",
    "hiperparametros_csv = os.path.join(current_folder, 'hiperparametros', 'random_forest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "La limpieza ya corrió en este Kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\7506-datos-tp2\\Features\\..\\Limpieza.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m'limpieza_runned'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'La limpieza ya corrió en este Kernel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mlimpieza_runned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: La limpieza ya corrió en este Kernel"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "La limpieza ya corrió en este Kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\7506-datos-tp2\\Features\\..\\Limpieza.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m'limpieza_runned'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'La limpieza ya corrió en este Kernel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mlimpieza_runned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: La limpieza ya corrió en este Kernel"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "La limpieza ya corrió en este Kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\7506-datos-tp2\\Features\\..\\Limpieza.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m'limpieza_runned'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'La limpieza ya corrió en este Kernel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mlimpieza_runned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: La limpieza ya corrió en este Kernel"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "%run $merge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(df_features.shape[0] == df['person'].unique().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargo los sets de entrenamiento, testing y predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run $set_de_entrenamiento_testing_y_prediccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento rápido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = labels_training.merge(df_features, how='inner', on='person')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'n_estimators':100, 'max_depth':10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = RandomForestRegressor(**param)\n",
    "regr.fit(training.drop('label', axis=1), training['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predigo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = labels_test.merge(df_features, how='inner', on='person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test['label_predicted'] = regr.predict(labels_test.drop('label', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc score: 0.889051084051084\n"
     ]
    }
   ],
   "source": [
    "%run $calcular_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importancia</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>columna</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dias ultimo checkout</th>\n",
       "      <td>0.232297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>screen_resolution_width std</th>\n",
       "      <td>0.060372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dias ultima compra</th>\n",
       "      <td>0.033849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days until 31-05 mean</th>\n",
       "      <td>0.026336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>viewed product</th>\n",
       "      <td>0.023903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_28</th>\n",
       "      <td>0.021554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>screen_resolution_height mean</th>\n",
       "      <td>0.019266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>screen_resolution_height std</th>\n",
       "      <td>0.019100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event_count</th>\n",
       "      <td>0.018363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days until 31-05 std</th>\n",
       "      <td>0.018282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cant visitas con Computadoras</th>\n",
       "      <td>0.015836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>screen_resolution_width mean</th>\n",
       "      <td>0.015011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand listing</th>\n",
       "      <td>0.014517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_1</th>\n",
       "      <td>0.012637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eventos Miercoles</th>\n",
       "      <td>0.012279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_18</th>\n",
       "      <td>0.012161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ad campaign hit</th>\n",
       "      <td>0.012100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_2</th>\n",
       "      <td>0.012066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_9</th>\n",
       "      <td>0.011542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_47</th>\n",
       "      <td>0.011524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_29</th>\n",
       "      <td>0.011398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eventos Martes</th>\n",
       "      <td>0.010780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_32</th>\n",
       "      <td>0.010280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eventos Jueves</th>\n",
       "      <td>0.010235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generic listing</th>\n",
       "      <td>0.010128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>searched products</th>\n",
       "      <td>0.009445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_41</th>\n",
       "      <td>0.008635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_43</th>\n",
       "      <td>0.008552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search engine hit</th>\n",
       "      <td>0.008472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eventos Lunes</th>\n",
       "      <td>0.008243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>madrugada</th>\n",
       "      <td>0.002664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_8</th>\n",
       "      <td>0.002480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_3</th>\n",
       "      <td>0.002477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_11</th>\n",
       "      <td>0.002341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compras Marzo</th>\n",
       "      <td>0.002315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thursday</th>\n",
       "      <td>0.002312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wednesday</th>\n",
       "      <td>0.002255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tarde</th>\n",
       "      <td>0.002152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_14</th>\n",
       "      <td>0.002096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_27</th>\n",
       "      <td>0.002068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_7</th>\n",
       "      <td>0.002067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_10</th>\n",
       "      <td>0.001954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_36</th>\n",
       "      <td>0.001847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuesday</th>\n",
       "      <td>0.001807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_30</th>\n",
       "      <td>0.001674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Saturday</th>\n",
       "      <td>0.001609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_13</th>\n",
       "      <td>0.001590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_46</th>\n",
       "      <td>0.001518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_35</th>\n",
       "      <td>0.001475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Friday</th>\n",
       "      <td>0.001451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_15</th>\n",
       "      <td>0.001318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monday</th>\n",
       "      <td>0.001214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead</th>\n",
       "      <td>0.001158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compras Abril</th>\n",
       "      <td>0.000999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compras Enero</th>\n",
       "      <td>0.000946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vive en Brasil</th>\n",
       "      <td>0.000903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_17</th>\n",
       "      <td>0.000729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sunday</th>\n",
       "      <td>0.000583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compras Febrero</th>\n",
       "      <td>0.000415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_4</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   importancia\n",
       "columna                                       \n",
       "dias ultimo checkout                  0.232297\n",
       "screen_resolution_width std           0.060372\n",
       "dias ultima compra                    0.033849\n",
       "days until 31-05 mean                 0.026336\n",
       "viewed product                        0.023903\n",
       "feature_hashing_timestamp_days_28     0.021554\n",
       "screen_resolution_height mean         0.019266\n",
       "screen_resolution_height std          0.019100\n",
       "event_count                           0.018363\n",
       "days until 31-05 std                  0.018282\n",
       "Cant visitas con Computadoras         0.015836\n",
       "screen_resolution_width mean          0.015011\n",
       "brand listing                         0.014517\n",
       "feature_hashing_timestamp_days_1      0.012637\n",
       "eventos Miercoles                     0.012279\n",
       "feature_hashing_timestamp_days_18     0.012161\n",
       "ad campaign hit                       0.012100\n",
       "feature_hashing_timestamp_days_2      0.012066\n",
       "feature_hashing_timestamp_days_9      0.011542\n",
       "feature_hashing_timestamp_days_47     0.011524\n",
       "feature_hashing_timestamp_days_29     0.011398\n",
       "eventos Martes                        0.010780\n",
       "feature_hashing_timestamp_days_32     0.010280\n",
       "eventos Jueves                        0.010235\n",
       "generic listing                       0.010128\n",
       "searched products                     0.009445\n",
       "feature_hashing_timestamp_days_41     0.008635\n",
       "feature_hashing_timestamp_days_43     0.008552\n",
       "search engine hit                     0.008472\n",
       "eventos Lunes                         0.008243\n",
       "...                                        ...\n",
       "madrugada                             0.002664\n",
       "feature_hashing_timestamp_days_8      0.002480\n",
       "feature_hashing_timestamp_days_3      0.002477\n",
       "feature_hashing_timestamp_days_11     0.002341\n",
       "compras Marzo                         0.002315\n",
       "Thursday                              0.002312\n",
       "Wednesday                             0.002255\n",
       "tarde                                 0.002152\n",
       "feature_hashing_timestamp_days_14     0.002096\n",
       "feature_hashing_timestamp_days_27     0.002068\n",
       "feature_hashing_timestamp_days_7      0.002067\n",
       "feature_hashing_timestamp_days_10     0.001954\n",
       "feature_hashing_timestamp_days_36     0.001847\n",
       "Tuesday                               0.001807\n",
       "feature_hashing_timestamp_days_30     0.001674\n",
       "Saturday                              0.001609\n",
       "feature_hashing_timestamp_days_13     0.001590\n",
       "feature_hashing_timestamp_days_46     0.001518\n",
       "feature_hashing_timestamp_days_35     0.001475\n",
       "Friday                                0.001451\n",
       "feature_hashing_timestamp_days_15     0.001318\n",
       "Monday                                0.001214\n",
       "lead                                  0.001158\n",
       "compras Abril                         0.000999\n",
       "compras Enero                         0.000946\n",
       "vive en Brasil                        0.000903\n",
       "feature_hashing_timestamp_days_17     0.000729\n",
       "Sunday                                0.000583\n",
       "compras Febrero                       0.000415\n",
       "feature_hashing_timestamp_days_4      0.000000\n",
       "\n",
       "[104 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance = pd.DataFrame(data={\n",
    "    'columna':training.drop('label', axis=1).columns,\n",
    "    'importancia':regr.feature_importances_\n",
    "}).set_index('columna')\n",
    "feature_importance.sort_values('importancia', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hiperparámetros\n",
    "\n",
    "En esta sección vamos a buscar los hiperparámetros de random forest con un Random Search y cross validation. Para construir este Random Search se usó como base el código de sklearn https://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html#sphx-glr-auto-examples-model-selection-plot-randomized-search-py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparámetros a probar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_with_features = labels.merge(df_features, how='inner', on='person')\n",
    "regr = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    \"n_estimators\": randint(1, 1000),\n",
    "    \"max_depth\": [3, 9, 12, 15, None],\n",
    "    \"max_features\": randint(1, labels_with_features.shape[1]),\n",
    "    \"min_samples_split\": randint(2, 11),\n",
    "    \"min_samples_leaf\": randint(2, 100),\n",
    "    \"bootstrap\": [True, False]\n",
    "}\n",
    "\n",
    "splits = 10 # cantidad de splits en el cross validation\n",
    "n_iter_search = 20 # cantidad de combinaciones, en total splits*n_iter_search RF a probar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota: hay más info en la consola desde la cual se corre jupyter.\n",
    "\n",
    "Se puede aumentar *n_jobs* para que corra más procesos en paralelo, pero se corre el riesgo de que se cuelgue por falta de memoria. Recomiendo que prueben ir aumentando *n_jobs* con un *n_iter_search* bajo hasta encontrar el mayor *n_jobs* que se banque su compu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed: 14.0min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed: 14.2min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed: 17.0min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed: 23.9min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed: 30.8min\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed: 32.5min\n",
      "[Parallel(n_jobs=2)]: Done  57 tasks      | elapsed: 39.4min\n",
      "[Parallel(n_jobs=2)]: Done  68 tasks      | elapsed: 41.2min\n",
      "[Parallel(n_jobs=2)]: Done  81 tasks      | elapsed: 48.9min\n",
      "[Parallel(n_jobs=2)]: Done  94 tasks      | elapsed: 56.8min\n",
      "[Parallel(n_jobs=2)]: Done 109 tasks      | elapsed: 64.9min\n",
      "[Parallel(n_jobs=2)]: Done 124 tasks      | elapsed: 69.1min\n",
      "[Parallel(n_jobs=2)]: Done 141 tasks      | elapsed: 76.1min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 96.6min\n",
      "[Parallel(n_jobs=2)]: Done 177 tasks      | elapsed: 112.5min\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed: 124.1min\n",
      "[Parallel(n_jobs=2)]: Done 200 out of 200 | elapsed: 126.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 7631.55 seconds for 20 candidates parameter settings.\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(regr, param_distributions=param_dist, iid=False, refit=True, verbose=10,\n",
    "                                   return_train_score=True, n_iter=n_iter_search, cv=splits,\n",
    "                                   scoring=make_scorer(roc_auc_score), n_jobs=2);\n",
    "\n",
    "start = time()\n",
    "random_search.fit(labels_with_features.drop('label', axis=1), labels_with_features['label'])\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El **mejor** Random Forest fue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.8771930215994177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 9,\n",
       " 'max_features': 37,\n",
       " 'min_samples_leaf': 30,\n",
       " 'min_samples_split': 7,\n",
       " 'n_estimators': 784}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('score: {}'.format(random_search.best_score_))\n",
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado de la búsqueda la podemos importar a un DataFrame de Pandas y analizarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>159.415562</td>\n",
       "      <td>4.593273</td>\n",
       "      <td>0.184806</td>\n",
       "      <td>0.037099</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>81</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>636</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 12, 'max_feat...</td>\n",
       "      <td>0.866330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951610</td>\n",
       "      <td>0.951909</td>\n",
       "      <td>0.952092</td>\n",
       "      <td>0.951903</td>\n",
       "      <td>0.951359</td>\n",
       "      <td>0.953499</td>\n",
       "      <td>0.950522</td>\n",
       "      <td>0.952397</td>\n",
       "      <td>0.952049</td>\n",
       "      <td>0.951177</td>\n",
       "      <td>0.951852</td>\n",
       "      <td>0.000751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.942321</td>\n",
       "      <td>0.348438</td>\n",
       "      <td>0.024235</td>\n",
       "      <td>0.004209</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>29</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>{'bootstrap': False, 'max_depth': None, 'max_f...</td>\n",
       "      <td>0.863274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919832</td>\n",
       "      <td>0.918047</td>\n",
       "      <td>0.918842</td>\n",
       "      <td>0.919527</td>\n",
       "      <td>0.918467</td>\n",
       "      <td>0.919935</td>\n",
       "      <td>0.917920</td>\n",
       "      <td>0.918561</td>\n",
       "      <td>0.918789</td>\n",
       "      <td>0.918826</td>\n",
       "      <td>0.918875</td>\n",
       "      <td>0.000659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0     159.415562      4.593273         0.184806        0.037099   \n",
       "1       7.942321      0.348438         0.024235        0.004209   \n",
       "\n",
       "  param_bootstrap param_max_depth param_max_features param_min_samples_leaf  \\\n",
       "0            True              12                 81                     15   \n",
       "1           False            None                 29                     87   \n",
       "\n",
       "  param_min_samples_split param_n_estimators  \\\n",
       "0                       7                636   \n",
       "1                       2                 59   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'bootstrap': True, 'max_depth': 12, 'max_feat...           0.866330   \n",
       "1  {'bootstrap': False, 'max_depth': None, 'max_f...           0.863274   \n",
       "\n",
       "        ...         split0_train_score  split1_train_score  \\\n",
       "0       ...                   0.951610            0.951909   \n",
       "1       ...                   0.919832            0.918047   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.952092            0.951903            0.951359   \n",
       "1            0.918842            0.919527            0.918467   \n",
       "\n",
       "   split5_train_score  split6_train_score  split7_train_score  \\\n",
       "0            0.953499            0.950522            0.952397   \n",
       "1            0.919935            0.917920            0.918561   \n",
       "\n",
       "   split8_train_score  split9_train_score  mean_train_score  std_train_score  \n",
       "0            0.952049            0.951177          0.951852         0.000751  \n",
       "1            0.918789            0.918826          0.918875         0.000659  \n",
       "\n",
       "[2 rows x 36 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_training = pd.DataFrame(data=random_search.cv_results_)\n",
    "stats_training.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escribo el mejor resultado en un archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = random_search.best_params_.copy()\n",
    "data['features'] = ','.join([f for f in labels_with_features.columns if f != 'label'])\n",
    "data['auc'] = random_search.best_score_\n",
    "data['cv'] = splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>cv</th>\n",
       "      <th>auc</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fecha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-11-24 19:50</th>\n",
       "      <td>False</td>\n",
       "      <td>9.0</td>\n",
       "      <td>65</td>\n",
       "      <td>91</td>\n",
       "      <td>7</td>\n",
       "      <td>104</td>\n",
       "      <td>10</td>\n",
       "      <td>0.859541</td>\n",
       "      <td>screen_resolution_height,screen_resolution_wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-24 20:51</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "      <td>67</td>\n",
       "      <td>10</td>\n",
       "      <td>253</td>\n",
       "      <td>10</td>\n",
       "      <td>0.860532</td>\n",
       "      <td>screen_resolution_height,screen_resolution_wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-26 17:13</th>\n",
       "      <td>False</td>\n",
       "      <td>15.0</td>\n",
       "      <td>97</td>\n",
       "      <td>83</td>\n",
       "      <td>7</td>\n",
       "      <td>994</td>\n",
       "      <td>10</td>\n",
       "      <td>0.860743</td>\n",
       "      <td>screen_resolution_height,screen_resolution_wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-27 00:28</th>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86</td>\n",
       "      <td>77</td>\n",
       "      <td>8</td>\n",
       "      <td>186</td>\n",
       "      <td>10</td>\n",
       "      <td>0.864988</td>\n",
       "      <td>screen_resolution_height mean,screen_resolutio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-29 18:11</th>\n",
       "      <td>True</td>\n",
       "      <td>9.0</td>\n",
       "      <td>37</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>784</td>\n",
       "      <td>10</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>screen_resolution_height mean,screen_resolutio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  bootstrap  max_depth  max_features  min_samples_leaf  \\\n",
       "fecha                                                                    \n",
       "2018-11-24 19:50      False        9.0            65                91   \n",
       "2018-11-24 20:51      False        NaN            55                67   \n",
       "2018-11-26 17:13      False       15.0            97                83   \n",
       "2018-11-27 00:28       True        NaN            86                77   \n",
       "2018-11-29 18:11       True        9.0            37                30   \n",
       "\n",
       "                  min_samples_split  n_estimators  cv       auc  \\\n",
       "fecha                                                             \n",
       "2018-11-24 19:50                  7           104  10  0.859541   \n",
       "2018-11-24 20:51                 10           253  10  0.860532   \n",
       "2018-11-26 17:13                  7           994  10  0.860743   \n",
       "2018-11-27 00:28                  8           186  10  0.864988   \n",
       "2018-11-29 18:11                  7           784  10  0.877193   \n",
       "\n",
       "                                                           features  \n",
       "fecha                                                                \n",
       "2018-11-24 19:50  screen_resolution_height,screen_resolution_wid...  \n",
       "2018-11-24 20:51  screen_resolution_height,screen_resolution_wid...  \n",
       "2018-11-26 17:13  screen_resolution_height,screen_resolution_wid...  \n",
       "2018-11-27 00:28  screen_resolution_height mean,screen_resolutio...  \n",
       "2018-11-29 18:11  screen_resolution_height mean,screen_resolutio...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mejores_resultados = pd.read_csv(hiperparametros_csv, index_col='fecha')\n",
    "mejores_resultados.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_resultado = pd.DataFrame(data=data, index=[pd.datetime.now().strftime(\"%Y-%m-%d %H:%M\")])\n",
    "mejor_resultado.index.name = 'fecha'\n",
    "mejores_resultados = mejores_resultados.append(mejor_resultado, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejores_resultados.to_csv(hiperparametros_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

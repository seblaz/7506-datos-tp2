{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import randint\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '__file__' in locals():\n",
    "    current_folder = os.path.dirname(os.path.abspath(__file__))\n",
    "else:\n",
    "    current_folder = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_features = '\"{}\"'.format(os.path.join(current_folder, '..', 'Features', 'Merge features.ipynb'))\n",
    "calcular_auc = '\"{}\"'.format(os.path.join(current_folder, '..', 'Calcular AUC.ipynb'))\n",
    "set_de_entrenamiento_testing_y_prediccion = '\"{}\"'.format(os.path.join(\n",
    "    current_folder,\n",
    "    '..',\n",
    "    'Set de entrenamiento, testing y predicción.ipynb'\n",
    "))\n",
    "hiperparametros_csv = os.path.join(current_folder, 'hiperparametros', 'random_forest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.12437, 3.07057]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "La limpieza ya corrió en este Kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/DATOS/UBA/Organizacion de Datos/tp2/Features/../Limpieza.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'limpieza_runned'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'La limpieza ya corrió en este Kernel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlimpieza_runned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: La limpieza ya corrió en este Kernel"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "La limpieza ya corrió en este Kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/DATOS/UBA/Organizacion de Datos/tp2/Features/../Limpieza.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'limpieza_runned'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'La limpieza ya corrió en este Kernel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlimpieza_runned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: La limpieza ya corrió en este Kernel"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "La limpieza ya corrió en este Kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/DATOS/UBA/Organizacion de Datos/tp2/Features/../Limpieza.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'limpieza_runned'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'La limpieza ya corrió en este Kernel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlimpieza_runned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: La limpieza ya corrió en este Kernel"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "%run $merge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(df_features.shape[0] == df['person'].unique().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargo los sets de entrenamiento, testing y predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run $set_de_entrenamiento_testing_y_prediccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento rápido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = labels_training.merge(df_features, how='inner', on='person')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'n_estimators':100, 'max_depth':10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = RandomForestRegressor(**param)\n",
    "regr.fit(training.drop('label', axis=1), training['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predigo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = labels_test.merge(df_features, how='inner', on='person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test['label_predicted'] = regr.predict(labels_test.drop('label', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc score: 0.832395409891599\n"
     ]
    }
   ],
   "source": [
    "%run $calcular_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importancia</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>columna</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>checkout</th>\n",
       "      <td>0.150033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days until 31-05 mean</th>\n",
       "      <td>0.077674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days until 31-05 std</th>\n",
       "      <td>0.052075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event_count</th>\n",
       "      <td>0.033119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>viewed product</th>\n",
       "      <td>0.032051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dias ultima compra</th>\n",
       "      <td>0.028888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cant visitas con Computadoras</th>\n",
       "      <td>0.027832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand listing</th>\n",
       "      <td>0.026347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cant visitas con smartphone</th>\n",
       "      <td>0.024597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eventos Martes</th>\n",
       "      <td>0.024556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eventos Jueves</th>\n",
       "      <td>0.024485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ad campaign hit</th>\n",
       "      <td>0.023881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generic listing</th>\n",
       "      <td>0.022141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>screen_resolution_width</th>\n",
       "      <td>0.021410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>screen_resolution_height</th>\n",
       "      <td>0.018483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eventos Domingo</th>\n",
       "      <td>0.018251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eventos Viernes</th>\n",
       "      <td>0.018186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>searched products</th>\n",
       "      <td>0.017622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eventos Miercoles</th>\n",
       "      <td>0.016184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search engine hit</th>\n",
       "      <td>0.015517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eventos Lunes</th>\n",
       "      <td>0.015120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minas Gerais</th>\n",
       "      <td>0.013142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eventos Sabado</th>\n",
       "      <td>0.013103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sao Paulo</th>\n",
       "      <td>0.012967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eventos madrugada_x</th>\n",
       "      <td>0.012405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rio Grande do Sul</th>\n",
       "      <td>0.012230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eventos tarde_y</th>\n",
       "      <td>0.012094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eventos tarde_x</th>\n",
       "      <td>0.011789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversion</th>\n",
       "      <td>0.011660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visited site</th>\n",
       "      <td>0.010868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hesse</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hainaut Province</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neuquen</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>England</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seoul</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>County Cork</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delaware</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roraima</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Departamento de La Paz</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Departamento de Montevideo</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rhône</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quezon</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quebec</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Provincia di Lecce</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Praia</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Porto</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Departamento de Santa Cruz</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pennsylvania</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Paris</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Departamento del Alto Parana</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dhaka</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>El Beni</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oujda-Angad</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ontario</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oklahoma</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nuevo León</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Northwest Territories</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               importancia\n",
       "columna                                   \n",
       "checkout                          0.150033\n",
       "days until 31-05 mean             0.077674\n",
       "days until 31-05 std              0.052075\n",
       "event_count                       0.033119\n",
       "viewed product                    0.032051\n",
       "dias ultima compra                0.028888\n",
       "Cant visitas con Computadoras     0.027832\n",
       "brand listing                     0.026347\n",
       "Cant visitas con smartphone       0.024597\n",
       "eventos Martes                    0.024556\n",
       "eventos Jueves                    0.024485\n",
       "ad campaign hit                   0.023881\n",
       "generic listing                   0.022141\n",
       "screen_resolution_width           0.021410\n",
       "screen_resolution_height          0.018483\n",
       "eventos Domingo                   0.018251\n",
       "eventos Viernes                   0.018186\n",
       "searched products                 0.017622\n",
       "eventos Miercoles                 0.016184\n",
       "search engine hit                 0.015517\n",
       "eventos Lunes                     0.015120\n",
       "Minas Gerais                      0.013142\n",
       "eventos Sabado                    0.013103\n",
       "Sao Paulo                         0.012967\n",
       "eventos madrugada_x               0.012405\n",
       "Rio Grande do Sul                 0.012230\n",
       "eventos tarde_y                   0.012094\n",
       "eventos tarde_x                   0.011789\n",
       "conversion                        0.011660\n",
       "visited site                      0.010868\n",
       "...                                    ...\n",
       "Hesse                             0.000000\n",
       "Hainaut Province                  0.000000\n",
       "Neuquen                           0.000000\n",
       "New York                          0.000000\n",
       "North                             0.000000\n",
       "England                           0.000000\n",
       "Seoul                             0.000000\n",
       "County Cork                       0.000000\n",
       "Delaware                          0.000000\n",
       "Roraima                           0.000000\n",
       "Departamento de La Paz            0.000000\n",
       "Departamento de Montevideo        0.000000\n",
       "Rhône                             0.000000\n",
       "Quezon                            0.000000\n",
       "Quebec                            0.000000\n",
       "Provincia di Lecce                0.000000\n",
       "Praia                             0.000000\n",
       "Porto                             0.000000\n",
       "Departamento de Santa Cruz        0.000000\n",
       "Pennsylvania                      0.000000\n",
       "Paris                             0.000000\n",
       "Departamento del Alto Parana      0.000000\n",
       "Dhaka                             0.000000\n",
       "El Beni                           0.000000\n",
       "Oujda-Angad                       0.000000\n",
       "Ontario                           0.000000\n",
       "Oklahoma                          0.000000\n",
       "Ohio                              0.000000\n",
       "Nuevo León                        0.000000\n",
       "Northwest Territories             0.000000\n",
       "\n",
       "[172 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance = pd.DataFrame(data={\n",
    "    'columna':training.drop('label', axis=1).columns,\n",
    "    'importancia':regr.feature_importances_\n",
    "}).set_index('columna')\n",
    "feature_importance.sort_values('importancia', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hiperparámetros\n",
    "\n",
    "En esta sección vamos a buscar los hiperparámetros de random forest con un Random Search y cross validation. Para construir este Random Search se usó como base el código de sklearn https://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html#sphx-glr-auto-examples-model-selection-plot-randomized-search-py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparámetros a probar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_with_features = labels.merge(df_features, how='inner', on='person')\n",
    "regr = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    \"n_estimators\": randint(1, 1000),\n",
    "    \"max_depth\": [3, 9, 12, 15, None],\n",
    "    \"max_features\": randint(1, labels_with_features.shape[1]),\n",
    "    \"min_samples_split\": randint(2, 11),\n",
    "    \"min_samples_leaf\": randint(2, 100),\n",
    "    \"bootstrap\": [True, False]\n",
    "}\n",
    "\n",
    "splits = 10 # cantidad de splits en el cross validation\n",
    "n_iter_search = 20 # cantidad de combinaciones, en total splits*n_iter_search RF a probar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota: hay más info en la consola desde la cual se corre jupyter.\n",
    "\n",
    "Se puede aumentar *n_jobs* para que corra más procesos en paralelo, pero se corre el riesgo de que se cuelgue por falta de memoria. Recomiendo que prueben ir aumentando *n_jobs* con un *n_iter_search* bajo hasta encontrar el mayor *n_jobs* que se banque su compu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   28.9s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   56.7s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=2)]: Done  57 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=2)]: Done  68 tasks      | elapsed: 13.9min\n",
      "[Parallel(n_jobs=2)]: Done  81 tasks      | elapsed: 23.7min\n",
      "[Parallel(n_jobs=2)]: Done  94 tasks      | elapsed: 27.9min\n",
      "[Parallel(n_jobs=2)]: Done 109 tasks      | elapsed: 31.2min\n",
      "[Parallel(n_jobs=2)]: Done 124 tasks      | elapsed: 33.3min\n",
      "[Parallel(n_jobs=2)]: Done 141 tasks      | elapsed: 37.8min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 39.7min\n",
      "[Parallel(n_jobs=2)]: Done 177 tasks      | elapsed: 47.3min\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed: 58.0min\n",
      "[Parallel(n_jobs=2)]: Done 200 out of 200 | elapsed: 59.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 3598.42 seconds for 20 candidates parameter settings.\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(regr, param_distributions=param_dist, iid=False, refit=True, verbose=10,\n",
    "                                   return_train_score=True, n_iter=n_iter_search, cv=splits,\n",
    "                                   scoring=make_scorer(roc_auc_score), n_jobs=2);\n",
    "\n",
    "start = time()\n",
    "random_search.fit(labels_with_features.drop('label', axis=1), labels_with_features['label'])\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El **mejor** Random Forest fue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.8605316495686459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': None,\n",
       " 'max_features': 55,\n",
       " 'min_samples_leaf': 67,\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 253}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('score: {}'.format(random_search.best_score_))\n",
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado de la búsqueda la podemos importar a un DataFrame de Pandas y analizarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.352844</td>\n",
       "      <td>0.150411</td>\n",
       "      <td>0.856557</td>\n",
       "      <td>0.975477</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>94</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>371</td>\n",
       "      <td>{'min_samples_leaf': 11, 'n_estimators': 371, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875373</td>\n",
       "      <td>0.975423</td>\n",
       "      <td>0.855958</td>\n",
       "      <td>0.975180</td>\n",
       "      <td>0.864083</td>\n",
       "      <td>0.975996</td>\n",
       "      <td>0.850868</td>\n",
       "      <td>0.975413</td>\n",
       "      <td>1.176354</td>\n",
       "      <td>0.043885</td>\n",
       "      <td>0.012797</td>\n",
       "      <td>0.000304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.880610</td>\n",
       "      <td>0.293911</td>\n",
       "      <td>0.859146</td>\n",
       "      <td>0.901806</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "      <td>69</td>\n",
       "      <td>71</td>\n",
       "      <td>6</td>\n",
       "      <td>953</td>\n",
       "      <td>{'min_samples_leaf': 71, 'n_estimators': 953, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.877337</td>\n",
       "      <td>0.900315</td>\n",
       "      <td>0.865598</td>\n",
       "      <td>0.901689</td>\n",
       "      <td>0.865165</td>\n",
       "      <td>0.901685</td>\n",
       "      <td>0.849889</td>\n",
       "      <td>0.901744</td>\n",
       "      <td>0.396681</td>\n",
       "      <td>0.040997</td>\n",
       "      <td>0.013597</td>\n",
       "      <td>0.001033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0      25.352844         0.150411         0.856557          0.975477   \n",
       "1      32.880610         0.293911         0.859146          0.901806   \n",
       "\n",
       "  param_bootstrap param_max_depth param_max_features param_min_samples_leaf  \\\n",
       "0            True            None                 94                     11   \n",
       "1            True              15                 69                     71   \n",
       "\n",
       "  param_min_samples_split param_n_estimators  \\\n",
       "0                       7                371   \n",
       "1                       6                953   \n",
       "\n",
       "                                              params  rank_test_score  \\\n",
       "0  {'min_samples_leaf': 11, 'n_estimators': 371, ...                9   \n",
       "1  {'min_samples_leaf': 71, 'n_estimators': 953, ...                3   \n",
       "\n",
       "        ...         split6_test_score  split6_train_score  split7_test_score  \\\n",
       "0       ...                  0.875373            0.975423           0.855958   \n",
       "1       ...                  0.877337            0.900315           0.865598   \n",
       "\n",
       "   split7_train_score  split8_test_score  split8_train_score  \\\n",
       "0            0.975180           0.864083            0.975996   \n",
       "1            0.901689           0.865165            0.901685   \n",
       "\n",
       "   split9_test_score  split9_train_score  std_fit_time  std_score_time  \\\n",
       "0           0.850868            0.975413      1.176354        0.043885   \n",
       "1           0.849889            0.901744      0.396681        0.040997   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.012797         0.000304  \n",
       "1        0.013597         0.001033  \n",
       "\n",
       "[2 rows x 36 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_training = pd.DataFrame(data=random_search.cv_results_)\n",
    "stats_training.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escribo el mejor resultado en un archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = random_search.best_params_.copy()\n",
    "data['features'] = ','.join([f for f in labels_with_features.columns if f != 'label'])\n",
    "data['auc'] = random_search.best_score_\n",
    "data['cv'] = splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>cv</th>\n",
       "      <th>auc</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fecha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-11-24 19:50</th>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>65</td>\n",
       "      <td>91</td>\n",
       "      <td>7</td>\n",
       "      <td>104</td>\n",
       "      <td>10</td>\n",
       "      <td>0.859541</td>\n",
       "      <td>screen_resolution_height,screen_resolution_wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  bootstrap  max_depth  max_features  min_samples_leaf  \\\n",
       "fecha                                                                    \n",
       "2018-11-24 19:50      False          9            65                91   \n",
       "\n",
       "                  min_samples_split  n_estimators  cv       auc  \\\n",
       "fecha                                                             \n",
       "2018-11-24 19:50                  7           104  10  0.859541   \n",
       "\n",
       "                                                           features  \n",
       "fecha                                                                \n",
       "2018-11-24 19:50  screen_resolution_height,screen_resolution_wid...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mejores_resultados = pd.read_csv(hiperparametros_csv, index_col='fecha')\n",
    "mejores_resultados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_resultado = pd.DataFrame(data=data, index=[pd.datetime.now().strftime(\"%Y-%m-%d %H:%M\")])\n",
    "mejor_resultado.index.name = 'fecha'\n",
    "mejores_resultados = mejores_resultados.append(mejor_resultado, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejores_resultados.to_csv(hiperparametros_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import randint\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '__file__' in locals():\n",
    "    current_folder = os.path.dirname(os.path.abspath(__file__))\n",
    "else:\n",
    "    current_folder = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_features = '\"{}\"'.format(os.path.join(current_folder, '..', 'Features', 'Merge features.ipynb'))\n",
    "calcular_auc = '\"{}\"'.format(os.path.join(current_folder, '..', 'Calcular AUC.ipynb'))\n",
    "set_de_entrenamiento_testing_y_prediccion = '\"{}\"'.format(os.path.join(\n",
    "    current_folder,\n",
    "    '..',\n",
    "    'Set de entrenamiento, testing y predicción.ipynb'\n",
    "))\n",
    "hiperparametros_csv = os.path.join(current_folder, 'hiperparametros', 'random_forest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "La limpieza ya corrió en este Kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/Descargas/Predicting-user-conversions/Features/../Limpieza.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'limpieza_runned'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'La limpieza ya corrió en este Kernel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlimpieza_runned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: La limpieza ya corrió en este Kernel"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "La limpieza ya corrió en este Kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/Descargas/Predicting-user-conversions/Features/../Limpieza.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'limpieza_runned'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'La limpieza ya corrió en este Kernel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlimpieza_runned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: La limpieza ya corrió en este Kernel"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "La limpieza ya corrió en este Kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/Descargas/Predicting-user-conversions/Features/../Limpieza.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'limpieza_runned'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'La limpieza ya corrió en este Kernel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlimpieza_runned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: La limpieza ya corrió en este Kernel"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "%run $merge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(df_features.shape[0] == df['person'].unique().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargo los sets de entrenamiento, testing y predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run $set_de_entrenamiento_testing_y_prediccion\n",
    "\n",
    "labels_with_features = labels.merge(df_features, how='inner', on='person')\n",
    "data = labels_with_features.drop('label', axis=1)\n",
    "target = labels_with_features['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento rápido\n",
    "\n",
    "Obtenemos las métricas con cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'bootstrap': True,\n",
    "    'max_depth': 15,\n",
    "    'max_features': 124,\n",
    "    'min_samples_leaf': 74,\n",
    "    'min_samples_split': 6,\n",
    "    'n_estimators': 126\n",
    "}\n",
    "\n",
    "cv_splits = 10 # cantidad de splits en el cross validation\n",
    "\n",
    "regr = RandomForestRegressor(**param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.877153 (+/- 0.019050)\n",
      "CPU times: user 6min 16s, sys: 169 ms, total: 6min 16s\n",
      "Wall time: 6min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = cross_val_score(regr, data, target, cv=cv_splits, scoring='roc_auc')\n",
    "print(\"Accuracy: %0.6f (+/- %0.6f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.877668 (+/- 0.019484)\n",
      "CPU times: user 7min 6s, sys: 358 ms, total: 7min 7s\n",
      "Wall time: 7min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = cross_val_score(regr, data, target, cv=cv_splits, scoring='roc_auc')\n",
    "print(\"Accuracy: %0.6f (+/- %0.6f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.fit(data, target);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(data={\n",
    "    'columna':data.columns,\n",
    "    'importancia':regr.feature_importances_\n",
    "}).set_index('columna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashing_features = ['feature_hashing_timestamp_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importancia</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>columna</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dias ultimo checkout</th>\n",
       "      <td>0.451045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>screen_resolution_width std</th>\n",
       "      <td>0.092280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dias ultima compra</th>\n",
       "      <td>0.038472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>screen_resolution_height std</th>\n",
       "      <td>0.033460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>checkout</th>\n",
       "      <td>0.024643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interest</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compras Enero</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compras Abril</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vive en Brasil</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              importancia\n",
       "columna                                  \n",
       "dias ultimo checkout             0.451045\n",
       "screen_resolution_width std      0.092280\n",
       "dias ultima compra               0.038472\n",
       "screen_resolution_height std     0.033460\n",
       "checkout                         0.024643\n",
       "...                                   ...\n",
       "interest                         0.000000\n",
       "lead                             0.000000\n",
       "compras Enero                    0.000000\n",
       "compras Abril                    0.000000\n",
       "vive en Brasil                   0.000000\n",
       "\n",
       "[89 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for hashing_feature in hashing_features:\n",
    "    hashing_importance = feature_importance[feature_importance.index.str.startswith(hashing_feature)].sum()\n",
    "    feature_importance = feature_importance[~feature_importance.index.str.startswith(hashing_feature)]\n",
    "    feature_importance.loc[hashing_feature] = hashing_importance\n",
    "feature_importance.sort_values('importancia', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hiperparámetros\n",
    "\n",
    "En esta sección vamos a buscar los hiperparámetros de random forest con un Random Search y cross validation. Para construir este Random Search se usó como base el código de sklearn https://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html#sphx-glr-auto-examples-model-selection-plot-randomized-search-py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparámetros a probar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'n_estimators': list(range(1,150,5)),\n",
    "    'max_depth': list(range(5,80,5)),\n",
    "    'max_features': randint(1, data.shape[1]),\n",
    "    'min_samples_split': randint(2, 11),\n",
    "    'min_samples_leaf': randint(2, 100),\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "cv_splits = 10 # cantidad de splits en el cross validation\n",
    "n_iter_search = 20 # cantidad de puntos, en total splits*n_iter_search RF a probar\n",
    "\n",
    "regr = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota: hay más info en la consola desde la cual se corre jupyter.\n",
    "\n",
    "Se puede aumentar *n_jobs* para que corra más procesos en paralelo, pero se corre el riesgo de que se cuelgue por falta de memoria. Recomiendo que prueben ir aumentando *n_jobs* con un *n_iter_search* bajo hasta encontrar el mayor *n_jobs* que se banque su compu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   35.2s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=2)]: Done  57 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=2)]: Done  68 tasks      | elapsed: 17.8min\n",
      "[Parallel(n_jobs=2)]: Done  81 tasks      | elapsed: 20.1min\n",
      "[Parallel(n_jobs=2)]: Done  94 tasks      | elapsed: 20.5min\n",
      "[Parallel(n_jobs=2)]: Done 109 tasks      | elapsed: 25.5min\n",
      "[Parallel(n_jobs=2)]: Done 124 tasks      | elapsed: 26.9min\n",
      "[Parallel(n_jobs=2)]: Done 141 tasks      | elapsed: 28.9min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 34.1min\n",
      "[Parallel(n_jobs=2)]: Done 177 tasks      | elapsed: 36.5min\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed: 39.5min\n",
      "[Parallel(n_jobs=2)]: Done 200 out of 200 | elapsed: 40.1min finished\n",
      "/home/sebas/.envs/trocafone/lib/python3.6/site-packages/sklearn/model_selection/_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 2433.66 seconds for 20 candidates parameter settings.\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(regr, param_distributions=param_dist, iid=False, refit=True, verbose=10,\n",
    "                                   return_train_score=True, n_iter=n_iter_search, cv=cv_splits,\n",
    "                                   scoring='roc_auc', n_jobs=2);\n",
    "\n",
    "start = time()\n",
    "random_search.fit(data, target)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El **mejor** Random Forest fue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.8774373099031154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 65,\n",
       " 'max_features': 98,\n",
       " 'min_samples_leaf': 69,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 91}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('score: {}'.format(random_search.best_score_))\n",
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.8774373099031154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 65,\n",
       " 'max_features': 98,\n",
       " 'min_samples_leaf': 69,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 91}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('score: {}'.format(random_search.best_score_))\n",
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado de la búsqueda la podemos importar a un DataFrame de Pandas y analizarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.907773</td>\n",
       "      <td>3.875361</td>\n",
       "      <td>0.025259</td>\n",
       "      <td>0.008271</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "      <td>122</td>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "      <td>86</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 15, 'max_feat...</td>\n",
       "      <td>0.873626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.938307</td>\n",
       "      <td>0.937028</td>\n",
       "      <td>0.938874</td>\n",
       "      <td>0.937734</td>\n",
       "      <td>0.936894</td>\n",
       "      <td>0.938358</td>\n",
       "      <td>0.937021</td>\n",
       "      <td>0.937677</td>\n",
       "      <td>0.937373</td>\n",
       "      <td>0.937630</td>\n",
       "      <td>0.937689</td>\n",
       "      <td>0.000621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.289508</td>\n",
       "      <td>2.279432</td>\n",
       "      <td>0.018642</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "      <td>131</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "      <td>{'bootstrap': False, 'max_depth': 25, 'max_fea...</td>\n",
       "      <td>0.843863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.941290</td>\n",
       "      <td>0.943594</td>\n",
       "      <td>0.945471</td>\n",
       "      <td>0.944550</td>\n",
       "      <td>0.943853</td>\n",
       "      <td>0.944026</td>\n",
       "      <td>0.941173</td>\n",
       "      <td>0.941788</td>\n",
       "      <td>0.943397</td>\n",
       "      <td>0.941932</td>\n",
       "      <td>0.943107</td>\n",
       "      <td>0.001399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      32.907773      3.875361         0.025259        0.008271   \n",
       "1      33.289508      2.279432         0.018642        0.003461   \n",
       "\n",
       "  param_bootstrap param_max_depth param_max_features param_min_samples_leaf  \\\n",
       "0            True              15                122                     41   \n",
       "1           False              25                131                     42   \n",
       "\n",
       "  param_min_samples_split param_n_estimators  \\\n",
       "0                       7                 86   \n",
       "1                       8                 46   \n",
       "\n",
       "                                              params  split0_test_score  ...  \\\n",
       "0  {'bootstrap': True, 'max_depth': 15, 'max_feat...           0.873626  ...   \n",
       "1  {'bootstrap': False, 'max_depth': 25, 'max_fea...           0.843863  ...   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0            0.938307            0.937028            0.938874   \n",
       "1            0.941290            0.943594            0.945471   \n",
       "\n",
       "   split3_train_score  split4_train_score  split5_train_score  \\\n",
       "0            0.937734            0.936894            0.938358   \n",
       "1            0.944550            0.943853            0.944026   \n",
       "\n",
       "   split6_train_score  split7_train_score  split8_train_score  \\\n",
       "0            0.937021            0.937677            0.937373   \n",
       "1            0.941173            0.941788            0.943397   \n",
       "\n",
       "   split9_train_score  mean_train_score  std_train_score  \n",
       "0            0.937630          0.937689         0.000621  \n",
       "1            0.941932          0.943107         0.001399  \n",
       "\n",
       "[2 rows x 36 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_training = pd.DataFrame(data=random_search.cv_results_)\n",
    "stats_training.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escribo el mejor resultado en un archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_data = {\n",
    "    'algorithm': 'random_forest',\n",
    "    'hyperparameters': random_search.best_params_,\n",
    "    'cv_splits': cv_splits,\n",
    "    'auc': random_search.best_score_,\n",
    "    'features': data.columns\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i write_hyperparameters.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import randint\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '__file__' in locals():\n",
    "    current_folder = os.path.dirname(os.path.abspath(__file__))\n",
    "else:\n",
    "    current_folder = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_features = '\"{}\"'.format(os.path.join(current_folder, '..', 'Features', 'Merge features.ipynb'))\n",
    "calcular_auc = '\"{}\"'.format(os.path.join(current_folder, '..', 'Calcular AUC.ipynb'))\n",
    "set_de_entrenamiento_testing_y_prediccion = '\"{}\"'.format(os.path.join(\n",
    "    current_folder,\n",
    "    '..',\n",
    "    'Set de entrenamiento, testing y predicción.ipynb'\n",
    "))\n",
    "hiperparametros_csv = os.path.join(current_folder, 'hiperparametros', 'random_forest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "La limpieza ya corrió en este Kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\7506-datos-tp2\\Features\\..\\Limpieza.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m'limpieza_runned'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'La limpieza ya corrió en este Kernel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mlimpieza_runned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: La limpieza ya corrió en este Kernel"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "La limpieza ya corrió en este Kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\7506-datos-tp2\\Features\\..\\Limpieza.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m'limpieza_runned'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'La limpieza ya corrió en este Kernel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mlimpieza_runned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: La limpieza ya corrió en este Kernel"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "La limpieza ya corrió en este Kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\7506-datos-tp2\\Features\\..\\Limpieza.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m'limpieza_runned'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'La limpieza ya corrió en este Kernel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mlimpieza_runned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: La limpieza ya corrió en este Kernel"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "%run $merge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(df_features.shape[0] == df['person'].unique().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargo los sets de entrenamiento, testing y predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run $set_de_entrenamiento_testing_y_prediccion\n",
    "\n",
    "labels_with_features = labels.merge(df_features, how='inner', on='person')\n",
    "data = labels_with_features.drop('label', axis=1)\n",
    "target = labels_with_features['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento rápido\n",
    "\n",
    "Obtenemos las métricas con cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'n_estimators': 100\n",
    "}\n",
    "\n",
    "cv_splits = 10 # cantidad de splits en el cross validation\n",
    "\n",
    "regr = RandomForestRegressor(**param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.845585 (+/- 0.020962)\n",
      "Wall time: 11min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = cross_val_score(regr, data, target, cv=cv_splits, scoring='roc_auc')\n",
    "print(\"Accuracy: %0.6f (+/- %0.6f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importancia</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>columna</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dias ultimo checkout</th>\n",
       "      <td>0.104756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event_count</th>\n",
       "      <td>0.037656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>viewed product</th>\n",
       "      <td>0.035763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days until 31-05 mean</th>\n",
       "      <td>0.030530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>screen_resolution_width std</th>\n",
       "      <td>0.029182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>screen_resolution_width mean</th>\n",
       "      <td>0.022694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>screen_resolution_height mean</th>\n",
       "      <td>0.022415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days until 31-05 std</th>\n",
       "      <td>0.021463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand listing</th>\n",
       "      <td>0.020988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ad campaign hit</th>\n",
       "      <td>0.020750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generic listing</th>\n",
       "      <td>0.020087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_28</th>\n",
       "      <td>0.016838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search engine hit</th>\n",
       "      <td>0.015073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_18</th>\n",
       "      <td>0.014951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eventos Jueves</th>\n",
       "      <td>0.014886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_29</th>\n",
       "      <td>0.014783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eventos Miercoles</th>\n",
       "      <td>0.014444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eventos tarde_y</th>\n",
       "      <td>0.014405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eventos tarde_x</th>\n",
       "      <td>0.014373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dias ultima compra</th>\n",
       "      <td>0.014291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_47</th>\n",
       "      <td>0.014058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_9</th>\n",
       "      <td>0.013745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>searched products</th>\n",
       "      <td>0.013610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eventos noche_y</th>\n",
       "      <td>0.013342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eventos noche_x</th>\n",
       "      <td>0.013296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cant visitas con Computadoras</th>\n",
       "      <td>0.013160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eventos Lunes</th>\n",
       "      <td>0.012841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dias ultimo viewed product</th>\n",
       "      <td>0.012747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_32</th>\n",
       "      <td>0.012480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_2</th>\n",
       "      <td>0.012087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_8</th>\n",
       "      <td>0.002733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thursday</th>\n",
       "      <td>0.002605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vive en Brasil</th>\n",
       "      <td>0.002492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_30</th>\n",
       "      <td>0.002254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_35</th>\n",
       "      <td>0.002063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noche</th>\n",
       "      <td>0.002042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maniana</th>\n",
       "      <td>0.002031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_15</th>\n",
       "      <td>0.001952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_10</th>\n",
       "      <td>0.001847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead</th>\n",
       "      <td>0.001844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_7</th>\n",
       "      <td>0.001669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>madrugada</th>\n",
       "      <td>0.001641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tarde</th>\n",
       "      <td>0.001624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_46</th>\n",
       "      <td>0.001599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wednesday</th>\n",
       "      <td>0.001567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_13</th>\n",
       "      <td>0.001507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuesday</th>\n",
       "      <td>0.001470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_45</th>\n",
       "      <td>0.001349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_36</th>\n",
       "      <td>0.001249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_27</th>\n",
       "      <td>0.001192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Saturday</th>\n",
       "      <td>0.001153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monday</th>\n",
       "      <td>0.001027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Friday</th>\n",
       "      <td>0.000976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compras Marzo</th>\n",
       "      <td>0.000876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compras Enero</th>\n",
       "      <td>0.000565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compras Abril</th>\n",
       "      <td>0.000436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sunday</th>\n",
       "      <td>0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_17</th>\n",
       "      <td>0.000270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compras Febrero</th>\n",
       "      <td>0.000186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_hashing_timestamp_days_4</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   importancia\n",
       "columna                                       \n",
       "dias ultimo checkout                  0.104756\n",
       "event_count                           0.037656\n",
       "viewed product                        0.035763\n",
       "days until 31-05 mean                 0.030530\n",
       "screen_resolution_width std           0.029182\n",
       "screen_resolution_width mean          0.022694\n",
       "screen_resolution_height mean         0.022415\n",
       "days until 31-05 std                  0.021463\n",
       "brand listing                         0.020988\n",
       "ad campaign hit                       0.020750\n",
       "generic listing                       0.020087\n",
       "feature_hashing_timestamp_days_28     0.016838\n",
       "search engine hit                     0.015073\n",
       "feature_hashing_timestamp_days_18     0.014951\n",
       "eventos Jueves                        0.014886\n",
       "feature_hashing_timestamp_days_29     0.014783\n",
       "eventos Miercoles                     0.014444\n",
       "eventos tarde_y                       0.014405\n",
       "eventos tarde_x                       0.014373\n",
       "dias ultima compra                    0.014291\n",
       "feature_hashing_timestamp_days_47     0.014058\n",
       "feature_hashing_timestamp_days_9      0.013745\n",
       "searched products                     0.013610\n",
       "eventos noche_y                       0.013342\n",
       "eventos noche_x                       0.013296\n",
       "Cant visitas con Computadoras         0.013160\n",
       "eventos Lunes                         0.012841\n",
       "dias ultimo viewed product            0.012747\n",
       "feature_hashing_timestamp_days_32     0.012480\n",
       "feature_hashing_timestamp_days_2      0.012087\n",
       "...                                        ...\n",
       "feature_hashing_timestamp_days_8      0.002733\n",
       "Thursday                              0.002605\n",
       "vive en Brasil                        0.002492\n",
       "feature_hashing_timestamp_days_30     0.002254\n",
       "feature_hashing_timestamp_days_35     0.002063\n",
       "noche                                 0.002042\n",
       "maniana                               0.002031\n",
       "feature_hashing_timestamp_days_15     0.001952\n",
       "feature_hashing_timestamp_days_10     0.001847\n",
       "lead                                  0.001844\n",
       "feature_hashing_timestamp_days_7      0.001669\n",
       "madrugada                             0.001641\n",
       "tarde                                 0.001624\n",
       "feature_hashing_timestamp_days_46     0.001599\n",
       "Wednesday                             0.001567\n",
       "feature_hashing_timestamp_days_13     0.001507\n",
       "Tuesday                               0.001470\n",
       "feature_hashing_timestamp_days_45     0.001349\n",
       "feature_hashing_timestamp_days_36     0.001249\n",
       "feature_hashing_timestamp_days_27     0.001192\n",
       "Saturday                              0.001153\n",
       "Monday                                0.001027\n",
       "Friday                                0.000976\n",
       "compras Marzo                         0.000876\n",
       "compras Enero                         0.000565\n",
       "compras Abril                         0.000436\n",
       "Sunday                                0.000430\n",
       "feature_hashing_timestamp_days_17     0.000270\n",
       "compras Febrero                       0.000186\n",
       "feature_hashing_timestamp_days_4      0.000000\n",
       "\n",
       "[106 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.fit(data, target)\n",
    "feature_importance = pd.DataFrame(data={\n",
    "    'columna':data.columns,\n",
    "    'importancia':regr.feature_importances_\n",
    "}).set_index('columna')\n",
    "feature_importance.sort_values('importancia', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hiperparámetros\n",
    "\n",
    "En esta sección vamos a buscar los hiperparámetros de random forest con un Random Search y cross validation. Para construir este Random Search se usó como base el código de sklearn https://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html#sphx-glr-auto-examples-model-selection-plot-randomized-search-py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparámetros a probar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'n_estimators': list(range(1,150,5)),\n",
    "    'max_depth': list(range(5,80,5)),\n",
    "    'max_features': randint(1, data.shape[1]),\n",
    "    'min_samples_split': randint(2, 11),\n",
    "    'min_samples_leaf': randint(2, 100),\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "cv_splits = 10 # cantidad de splits en el cross validation\n",
    "n_iter_search = 1 # cantidad de puntos, en total splits*n_iter_search RF a probar\n",
    "\n",
    "regr = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota: hay más info en la consola desde la cual se corre jupyter.\n",
    "\n",
    "Se puede aumentar *n_jobs* para que corra más procesos en paralelo, pero se corre el riesgo de que se cuelgue por falta de memoria. Recomiendo que prueben ir aumentando *n_jobs* con un *n_iter_search* bajo hasta encontrar el mayor *n_jobs* que se banque su compu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   59.3s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 212.70 seconds for 1 candidates parameter settings.\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(regr, param_distributions=param_dist, iid=False, refit=True, verbose=10,\n",
    "                                   return_train_score=True, n_iter=n_iter_search, cv=cv_splits,\n",
    "                                   scoring='roc_auc', n_jobs=2);\n",
    "\n",
    "start = time()\n",
    "random_search.fit(data, target)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El **mejor** Random Forest fue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.8703461300583676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 35,\n",
       " 'max_features': 90,\n",
       " 'min_samples_leaf': 15,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 71}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('score: {}'.format(random_search.best_score_))\n",
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado de la búsqueda la podemos importar a un DataFrame de Pandas y analizarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.062374</td>\n",
       "      <td>0.476919</td>\n",
       "      <td>0.031018</td>\n",
       "      <td>0.002205</td>\n",
       "      <td>True</td>\n",
       "      <td>35</td>\n",
       "      <td>90</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 35, 'max_feat...</td>\n",
       "      <td>0.864919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965342</td>\n",
       "      <td>0.965016</td>\n",
       "      <td>0.966003</td>\n",
       "      <td>0.965218</td>\n",
       "      <td>0.964678</td>\n",
       "      <td>0.965055</td>\n",
       "      <td>0.96416</td>\n",
       "      <td>0.96494</td>\n",
       "      <td>0.966129</td>\n",
       "      <td>0.965753</td>\n",
       "      <td>0.965229</td>\n",
       "      <td>0.000575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      30.062374      0.476919         0.031018        0.002205   \n",
       "\n",
       "  param_bootstrap param_max_depth param_max_features param_min_samples_leaf  \\\n",
       "0            True              35                 90                     15   \n",
       "\n",
       "  param_min_samples_split param_n_estimators  \\\n",
       "0                       2                 71   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'bootstrap': True, 'max_depth': 35, 'max_feat...           0.864919   \n",
       "\n",
       "        ...         split0_train_score  split1_train_score  \\\n",
       "0       ...                   0.965342            0.965016   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.966003            0.965218            0.964678   \n",
       "\n",
       "   split5_train_score  split6_train_score  split7_train_score  \\\n",
       "0            0.965055             0.96416             0.96494   \n",
       "\n",
       "   split8_train_score  split9_train_score  mean_train_score  std_train_score  \n",
       "0            0.966129            0.965753          0.965229         0.000575  \n",
       "\n",
       "[1 rows x 36 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_training = pd.DataFrame(data=random_search.cv_results_)\n",
    "stats_training.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escribo el mejor resultado en un archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_data = {\n",
    "    'algorithm': 'random_forest',\n",
    "    'hyperparameters': random_search.best_params_,\n",
    "    'cv_splits': cv_splits,\n",
    "    'auc': random_search.best_score_,\n",
    "    'features': data.columns\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i write_hyperparameters.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

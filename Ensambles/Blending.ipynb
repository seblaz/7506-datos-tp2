{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blending ensembling\n",
    " - [Predictores base](#Predictores-base)\n",
    " - [Separación del 10%](#Separación-del-10%)\n",
    " - [Predicción para el Blending](#Predicción-para-el-Blending)\n",
    " - [Modelo Blender](#Modelo-Blender)\n",
    " - [Predicción del set testing con los modelos base](#Predicción-del-set-testing-con-los-modelos-base)\n",
    " - [Predicción del set testing con el blender](#Predicción-del-set-testing-con-el-blender)\n",
    "\n",
    "Repito con un super set de entrenamiento:\n",
    "\n",
    " - [Super set de entrenamiento](#Super-set-de-entrenamiento)\n",
    " - [Separación del 10% del super-set](#Separación-del-10%-del-super-set)\n",
    " - [Predicción para el super Blending](#Predicción-para-el-super-Blending)\n",
    " - [Modelo Blender con el super-set](#Modelo-Blender-con-el-super-set)\n",
    " - [Predicción del set de testing con los modelos base entrenados con el super-set de entrenamiento](#Predicción-del-set-de-testing-con-los-modelos-base-entrenados-con-el-super-set-de-entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBRegressor\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '__file__' in locals():\n",
    "    current_folder = os.path.dirname(os.path.abspath(__file__))\n",
    "else:\n",
    "    current_folder = os.getcwd()\n",
    "\n",
    "set_de_entrenamiento_testing_y_prediccion = '\"{}\"'.format(os.path.join(\n",
    "    current_folder,\n",
    "    '..',\n",
    "    'Set de entrenamiento, testing y predicción.ipynb'\n",
    "))\n",
    "merge_features = '\"{}\"'.format(os.path.join(current_folder, '..', 'Features', 'Merge features.ipynb'))\n",
    "predicciones_csv = os.path.join(current_folder, '..', 'predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargo el df con los features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "La limpieza ya corrió en este Kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/GitHub/7506-datos-tp2/Features/../Limpieza.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'limpieza_runned'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'La limpieza ya corrió en este Kernel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlimpieza_runned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: La limpieza ya corrió en este Kernel"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "La limpieza ya corrió en este Kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/GitHub/7506-datos-tp2/Features/../Limpieza.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'limpieza_runned'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'La limpieza ya corrió en este Kernel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlimpieza_runned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: La limpieza ya corrió en este Kernel"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "La limpieza ya corrió en este Kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/GitHub/7506-datos-tp2/Features/../Limpieza.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'limpieza_runned'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'La limpieza ya corrió en este Kernel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlimpieza_runned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: La limpieza ya corrió en este Kernel"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "%run $merge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(df_features.shape[0] == get_clean_df()['person'].unique().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargo el set de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run $set_de_entrenamiento_testing_y_prediccion\n",
    "\n",
    "labels_with_features = labels.merge(df_features, how='inner', on='person')\n",
    "train = labels_with_features.drop('label', axis=1)\n",
    "train_target = labels_with_features['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictores base\n",
    "\n",
    "En esta sección vamos a preparar los predictores base a utilizar. Estos son los mismos que se encuentran en la carpeta *Algoritmos de ML*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_predictors = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'n_estimators': 128,\n",
    "    'loss': 'linear',\n",
    "    'learning_rate': 0.07,\n",
    "    'base_estimator': DecisionTreeRegressor(criterion='mse', max_depth=4, max_features=None,\n",
    "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "            min_impurity_split=None, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            presort=False, random_state=None, splitter='best')\n",
    "}\n",
    "\n",
    "base_predictors.append(AdaBoostRegressor(**param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'bootstrap': True,\n",
    "    'max_depth': 10,\n",
    "    'max_features': 81,\n",
    "    'min_samples_leaf': 49,\n",
    "    'min_samples_split': 8,\n",
    "    'n_estimators': 56\n",
    "}\n",
    "\n",
    "base_predictors.append(RandomForestRegressor(**param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_predictors.append(DecisionTreeRegressor(criterion='mse', max_depth=4, max_features=None,\n",
    "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "            min_impurity_split=None, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            presort=False, random_state=None, splitter='best'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'objective': 'reg:logistic',\n",
    "    'colsample_bylevel': 0.6605668347627213,\n",
    "    'colsample_bytree': 0.5279014819087092,\n",
    "    'min_child_weight': 4.302125582335056,\n",
    "    'learning_rate': 0.15803667962605694,\n",
    "    'max_delta_step': 7.592652591386328,\n",
    "    'n_estimators': 65,\n",
    "    'reg_lambda': 1.1181195507921775,\n",
    "    'max_depth': 9,\n",
    "    'silent': True,\n",
    "    'subsample': 0.43744176565530823,\n",
    "    'reg_alpha': 3.845311207046479,\n",
    "    'gamma': 6.219264874528072\n",
    "}\n",
    "\n",
    "base_predictors.append(XGBRegressor(**param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separación del 10%\n",
    "\n",
    "Separo un 10% del set de entrenamiento para luego entrenar el blending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_90, train_10, train_90_target, train_10_target = train_test_split(train, train_target, test_size=0.1, stratify=train_target)\n",
    "assert(train_90.shape[0] == train_90_target.shape[0])\n",
    "assert(train_10.shape[0] == train_10_target.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción para el Blending\n",
    "\n",
    "Ahora vamos a realizar una predicción por cada predictor base del 10% separado, utilizando el 90% del set de entrenamiento (separando este 90% en sets de entrenamiento y validacion para optimizar cada modelo). Estas predicciones las vamos a agregar a una copia del set de entrenamiento (*train_blending_predictions*).\n",
    "\n",
    "**Nota**: falta hacer el cross validation con el 90% para encontrar los parámetros óptimos. Actualmento los parámetros están optimizados para el 100%. Esto implica una filtración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_10_with_base_predictions = train_10.copy()\n",
    "for predictor in base_predictors:\n",
    "    train_10_with_base_predictions[predictor.__class__.__name__] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.2 s, sys: 52 ms, total: 44.3 s\n",
      "Wall time: 1min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for predictor in base_predictors:\n",
    "    predictor.fit(train_90, train_90_target) # train\n",
    "    train_10_with_base_predictions[predictor.__class__.__name__] = predictor.predict(train_10) # predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_resolution_height mean</th>\n",
       "      <th>screen_resolution_width mean</th>\n",
       "      <th>screen_resolution_height std</th>\n",
       "      <th>screen_resolution_width std</th>\n",
       "      <th>ad campaign hit</th>\n",
       "      <th>brand listing</th>\n",
       "      <th>checkout</th>\n",
       "      <th>conversion</th>\n",
       "      <th>generic listing</th>\n",
       "      <th>lead</th>\n",
       "      <th>search engine hit</th>\n",
       "      <th>searched products</th>\n",
       "      <th>...</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>tarde</th>\n",
       "      <th>madrugada</th>\n",
       "      <th>maniana</th>\n",
       "      <th>tarde</th>\n",
       "      <th>noche</th>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <th>XGBRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fcb5fb33</th>\n",
       "      <td>480.0</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.058259</td>\n",
       "      <td>0.006396</td>\n",
       "      <td>0.008419</td>\n",
       "      <td>0.011864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51fdbb43</th>\n",
       "      <td>900.0</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038176</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.008419</td>\n",
       "      <td>0.006298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177bc00b</th>\n",
       "      <td>768.0</td>\n",
       "      <td>1109.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147.801669</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.447653</td>\n",
       "      <td>0.324053</td>\n",
       "      <td>0.212080</td>\n",
       "      <td>0.259470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          screen_resolution_height mean  screen_resolution_width mean  \\\n",
       "person                                                                  \n",
       "fcb5fb33                          480.0                    320.000000   \n",
       "51fdbb43                          900.0                   1600.000000   \n",
       "177bc00b                          768.0                   1109.333333   \n",
       "\n",
       "          screen_resolution_height std  screen_resolution_width std  \\\n",
       "person                                                                \n",
       "fcb5fb33                           0.0                     0.000000   \n",
       "51fdbb43                           0.0                     0.000000   \n",
       "177bc00b                           0.0                   147.801669   \n",
       "\n",
       "          ad campaign hit  brand listing  checkout  conversion  \\\n",
       "person                                                           \n",
       "fcb5fb33              0.0            0.0       1.0         0.0   \n",
       "51fdbb43              3.0            0.0       1.0         0.0   \n",
       "177bc00b              8.0           15.0       3.0         0.0   \n",
       "\n",
       "          generic listing  lead  search engine hit  searched products  \\\n",
       "person                                                                  \n",
       "fcb5fb33              5.0   0.0                0.0                2.0   \n",
       "51fdbb43              0.0   0.0                0.0                0.0   \n",
       "177bc00b              1.0   0.0                2.0                0.0   \n",
       "\n",
       "              ...       Sunday  Thursday  Tuesday  Wednesday  tarde  \\\n",
       "person        ...                                                     \n",
       "fcb5fb33      ...          0.0       0.0      0.0        0.0      0   \n",
       "51fdbb43      ...          0.0       0.0      0.0        0.0      0   \n",
       "177bc00b      ...          0.0       0.0      0.0        0.0      0   \n",
       "\n",
       "          madrugada  maniana  noche  AdaBoostRegressor  RandomForestRegressor  \\\n",
       "person                                                                          \n",
       "fcb5fb33          0        0      0           0.058259               0.006396   \n",
       "51fdbb43          0        0      0           0.038176               0.001690   \n",
       "177bc00b          0        0      0           0.447653               0.324053   \n",
       "\n",
       "          DecisionTreeRegressor  XGBRegressor  \n",
       "person                                         \n",
       "fcb5fb33               0.008419      0.011864  \n",
       "51fdbb43               0.008419      0.006298  \n",
       "177bc00b               0.212080      0.259470  \n",
       "\n",
       "[3 rows x 132 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_10_with_base_predictions.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Blender\n",
    "\n",
    "Entrenamos un modelo blender que use las predicciones de los modelos base (el 10% que separamos) para realizar las predicciones del set de tesing (el que está en kaggle).\n",
    "\n",
    "**Nota**: en este paso podríamos agregar algunos de los features originales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <th>XGBRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fcb5fb33</th>\n",
       "      <td>0.058259</td>\n",
       "      <td>0.006396</td>\n",
       "      <td>0.008419</td>\n",
       "      <td>0.011864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51fdbb43</th>\n",
       "      <td>0.038176</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.008419</td>\n",
       "      <td>0.006298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177bc00b</th>\n",
       "      <td>0.447653</td>\n",
       "      <td>0.324053</td>\n",
       "      <td>0.212080</td>\n",
       "      <td>0.259470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AdaBoostRegressor  RandomForestRegressor  DecisionTreeRegressor  \\\n",
       "person                                                                      \n",
       "fcb5fb33           0.058259               0.006396               0.008419   \n",
       "51fdbb43           0.038176               0.001690               0.008419   \n",
       "177bc00b           0.447653               0.324053               0.212080   \n",
       "\n",
       "          XGBRegressor  \n",
       "person                  \n",
       "fcb5fb33      0.011864  \n",
       "51fdbb43      0.006298  \n",
       "177bc00b      0.259470  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blend_train = train_10_with_base_predictions[[predictor.__class__.__name__ for predictor in base_predictors]]\n",
    "blend_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'solver': 'lbfgs'\n",
    "}\n",
    "blender = LogisticRegression(**param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.858502 (+/- 0.123263)\n",
      "CPU times: user 144 ms, sys: 0 ns, total: 144 ms\n",
      "Wall time: 360 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = cross_val_score(blender, blend_train, train_10_target, cv=10, scoring='roc_auc')\n",
    "print(\"Accuracy: %0.6f (+/- %0.6f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blender.fit(blend_train, train_10_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción del set testing con los modelos base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = labels_to_predict.merge(df_features, how='inner', on='person')\n",
    "assert(testing.shape[0] == labels_to_predict.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_with_base_predictions = testing.copy()\n",
    "for predictor in base_predictors:\n",
    "    testing_with_base_predictions[predictor.__class__.__name__] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.3 s, sys: 133 ms, total: 53.5 s\n",
      "Wall time: 53.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for predictor in base_predictors:\n",
    "    # como warm_start=False cada vez que llamo fit, el modelo se reinicia\n",
    "    predictor.fit(train, train_target) # train\n",
    "    testing_with_base_predictions[predictor.__class__.__name__] = predictor.predict(testing) # predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción del set testing con el blender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4886f805</th>\n",
       "      <td>0.038229</td>\n",
       "      <td>0.002735</td>\n",
       "      <td>0.007434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0297fc1e</th>\n",
       "      <td>0.143778</td>\n",
       "      <td>0.064331</td>\n",
       "      <td>0.039040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2d681dd8</th>\n",
       "      <td>0.038229</td>\n",
       "      <td>0.004466</td>\n",
       "      <td>0.007434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AdaBoostRegressor  RandomForestRegressor  DecisionTreeRegressor\n",
       "person                                                                   \n",
       "4886f805           0.038229               0.002735               0.007434\n",
       "0297fc1e           0.143778               0.064331               0.039040\n",
       "2d681dd8           0.038229               0.004466               0.007434"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_with_base_predictions_for_blender = testing_with_base_predictions[[predictor.__class__.__name__ for predictor in base_predictors]]\n",
    "testing_with_base_predictions_for_blender.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predecimos probabilidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esto es muy específico de logistic reggresion\n",
    "testing_target = pd.DataFrame(data=blender.predict_proba(testing_with_base_predictions_for_blender))[[1]]\n",
    "testing_target.index = testing_with_base_predictions_for_blender.index\n",
    "testing_target.index.name = 'person'\n",
    "testing_target.columns = ['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a probar prediciendo labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_target = pd.DataFrame(data=blender.predict(testing_with_base_predictions_for_blender))\n",
    "testing_target.index = testing_with_base_predictions_for_blender.index\n",
    "testing_target.index.name = 'person'\n",
    "testing_target.columns = ['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# si queremos aplicar blending normal:\n",
    "# testing_target.to_csv(predicciones_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super-set de entrenamiento\n",
    "\n",
    "Juntamos el set de testing y el de entrenamiento en un nuevo super-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_train = train.append(testing)\n",
    "super_train_target = train_target.append(testing_target['label'])\n",
    "assert(super_train.shape[0] == super_train_target.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separación del 10% del super-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ya no puedo usar stratify porque en super_train_target tengo 0, 1 y probabilidades\n",
    "super_train_90, super_train_10, super_train_90_target, super_train_10_target = train_test_split(super_train, super_train_target, test_size=0.1)\n",
    "assert(super_train_90.shape[0] == super_train_90_target.shape[0])\n",
    "assert(super_train_10.shape[0] == super_train_10_target.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción para el super Blending\n",
    "\n",
    "Ahora vamos a realizar una predicción por cada predictor base del 10% separado, utilizando el 90% del super-set de entrenamiento (separando este 90% en sets de entrenamiento y validacion para optimizar cada modelo). Estas predicciones las vamos a agregar a una copia del set de entrenamiento (*super_train_blending_predictions*).\n",
    "\n",
    "**Nota**: falta hacer el cross validation con el 90% para encontrar los parámetros óptimos. Actualmento los parámetros están optimizados para el 100% del set de entrenamiento original. Esto implica una filtración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_train_10_with_base_predictions = super_train_10.copy()\n",
    "for predictor in base_predictors:\n",
    "    super_train_10_with_base_predictions[predictor.__class__.__name__] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 56s, sys: 280 ms, total: 1min 56s\n",
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for predictor in base_predictors:\n",
    "    predictor.fit(super_train_90, super_train_90_target) # train\n",
    "    super_train_10_with_base_predictions[predictor.__class__.__name__] = predictor.predict(super_train_10) # predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Blender con el super-set\n",
    "\n",
    "Necesitamos un modelo en el cual los targets puedan ser floats, por eso no usamos LogisticRegression. En este caso decidimos utilizar xgboost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a8d906b0</th>\n",
       "      <td>0.409028</td>\n",
       "      <td>0.167797</td>\n",
       "      <td>0.102187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42316be2</th>\n",
       "      <td>0.029734</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>0.004667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37135eae</th>\n",
       "      <td>0.063227</td>\n",
       "      <td>0.006322</td>\n",
       "      <td>0.004667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AdaBoostRegressor  RandomForestRegressor  DecisionTreeRegressor\n",
       "person                                                                   \n",
       "a8d906b0           0.409028               0.167797               0.102187\n",
       "42316be2           0.029734               0.001610               0.004667\n",
       "37135eae           0.063227               0.006322               0.004667"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_blend_train = super_train_10_with_base_predictions[[predictor.__class__.__name__ for predictor in base_predictors]]\n",
    "super_blend_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "#     'n_estimators': 'lbfgs'\n",
    "    'solver': 'lbfgs'\n",
    "}\n",
    "super_blender = LogisticRegression(**param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.872336 (+/- 0.096028)\n",
      "CPU times: user 370 ms, sys: 50 ms, total: 420 ms\n",
      "Wall time: 112 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = cross_val_score(super_blender, super_blend_train, super_train_10_target, cv=10, scoring='roc_auc')\n",
    "print(\"Accuracy: %0.6f (+/- %0.6f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_blender.fit(super_blend_train, super_train_10_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción del set de testing con los modelos base entrenados con el super-set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_testing_with_base_predictions = testing.copy()\n",
    "for predictor in base_predictors:\n",
    "    super_testing_with_base_predictions[predictor.__class__.__name__] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 7s, sys: 365 ms, total: 2min 7s\n",
      "Wall time: 2min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for predictor in base_predictors:\n",
    "    # como warm_start=False cada vez que llamo fit, el modelo se reinicia\n",
    "    predictor.fit(super_train, super_train_target) # train\n",
    "    super_testing_with_base_predictions[predictor.__class__.__name__] = predictor.predict(testing) # predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción del set testing con el super blender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4886f805</th>\n",
       "      <td>0.031315</td>\n",
       "      <td>0.001652</td>\n",
       "      <td>0.003917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0297fc1e</th>\n",
       "      <td>0.140220</td>\n",
       "      <td>0.028422</td>\n",
       "      <td>0.023855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2d681dd8</th>\n",
       "      <td>0.031315</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>0.003917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AdaBoostRegressor  RandomForestRegressor  DecisionTreeRegressor\n",
       "person                                                                   \n",
       "4886f805           0.031315               0.001652               0.003917\n",
       "0297fc1e           0.140220               0.028422               0.023855\n",
       "2d681dd8           0.031315               0.002166               0.003917"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_with_base_predictions_for_super_blender = super_testing_with_base_predictions[[predictor.__class__.__name__ for predictor in base_predictors]]\n",
    "testing_with_base_predictions_for_super_blender.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4886f805</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0297fc1e</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2d681dd8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          label\n",
       "person         \n",
       "4886f805      0\n",
       "0297fc1e      0\n",
       "2d681dd8      0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = super_blender.predict(testing_with_base_predictions_for_super_blender)\n",
    "predictions = pd.DataFrame(data=predictions, index=testing_with_base_predictions_for_super_blender.index)\n",
    "predictions.columns = ['label']\n",
    "predictions.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions.to_csv(predicciones_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blending ensembling\n",
    " - [Predictores base](#Predictores-base)\n",
    " - [Separación del 10%](#Separación-del-10%)\n",
    " - [Predicción para el Blending](#Predicción-para-el-Blending)\n",
    " - [Modelo Blender](#Modelo-Blender)\n",
    " - [Predicción del set testing con los modelos base](#Predicción-del-set-testing-con-los-modelos-base)\n",
    " - [Predicción del set testing con el blender](#Predicción-del-set-testing-con-el-blender)\n",
    "\n",
    "Repito con un super set de entrenamiento:\n",
    "\n",
    " - [Super set de entrenamiento](#Super-set-de-entrenamiento)\n",
    " - [Separación del 10% del super-set](#Separación-del-10%-del-super-set)\n",
    " - [Predicción para el super Blending](#Predicción-para-el-super-Blending)\n",
    " - [Modelo Blender con el super-set](#Modelo-Blender-con-el-super-set)\n",
    " - [Predicción del set de testing con los modelos base entrenados con el super-set de entrenamiento](#Predicción-del-set-de-testing-con-los-modelos-base-entrenados-con-el-super-set-de-entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBRegressor\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '__file__' in locals():\n",
    "    current_folder = os.path.dirname(os.path.abspath(__file__))\n",
    "else:\n",
    "    current_folder = os.getcwd()\n",
    "\n",
    "set_de_entrenamiento_testing_y_prediccion = '\"{}\"'.format(os.path.join(\n",
    "    current_folder,\n",
    "    '..',\n",
    "    'Set de entrenamiento, testing y predicción.ipynb'\n",
    "))\n",
    "merge_features = '\"{}\"'.format(os.path.join(current_folder, '..', 'Features', 'Merge features.ipynb'))\n",
    "predicciones_csv = os.path.join(current_folder, '..', 'predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargo el df con los features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "La limpieza ya corrió en este Kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/DATOS/UBA/Organizacion de Datos/tp2/Features/../Limpieza.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'limpieza_runned'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'La limpieza ya corrió en este Kernel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlimpieza_runned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: La limpieza ya corrió en este Kernel"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "La limpieza ya corrió en este Kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/DATOS/UBA/Organizacion de Datos/tp2/Features/../Limpieza.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'limpieza_runned'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'La limpieza ya corrió en este Kernel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlimpieza_runned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: La limpieza ya corrió en este Kernel"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "La limpieza ya corrió en este Kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/DATOS/UBA/Organizacion de Datos/tp2/Features/../Limpieza.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'limpieza_runned'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'La limpieza ya corrió en este Kernel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlimpieza_runned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: La limpieza ya corrió en este Kernel"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "%run $merge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(df_features.shape[0] == get_clean_df()['person'].unique().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargo el set de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run $set_de_entrenamiento_testing_y_prediccion\n",
    "\n",
    "labels_with_features = labels.merge(df_features, how='inner', on='person')\n",
    "train = labels_with_features.drop('label', axis=1)\n",
    "train_target = labels_with_features['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictores base\n",
    "\n",
    "En esta sección vamos a preparar los predictores base a utilizar. Estos son los mismos que se encuentran en la carpeta *Algoritmos de ML*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_predictors = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'n_estimators': 128,\n",
    "    'loss': 'linear',\n",
    "    'learning_rate': 0.07,\n",
    "    'base_estimator': DecisionTreeRegressor(criterion='mse', max_depth=4, max_features=None,\n",
    "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "            min_impurity_split=None, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            presort=False, random_state=None, splitter='best')\n",
    "}\n",
    "\n",
    "base_predictors.append(AdaBoostRegressor(**param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'bootstrap': True,\n",
    "    'max_depth': 9,\n",
    "    'max_features': 37,\n",
    "    'min_samples_leaf': 30,\n",
    "    'min_samples_split': 7,\n",
    "    'n_estimators': 784\n",
    "}\n",
    "\n",
    "base_predictors.append(RandomForestRegressor(**param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_predictors.append(DecisionTreeRegressor(criterion='mse', max_depth=4, max_features=None,\n",
    "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "            min_impurity_split=None, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            presort=False, random_state=None, splitter='best'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separación del 10%\n",
    "\n",
    "Separo un 10% del set de entrenamiento para luego entrenar el blending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_90, train_10, train_90_target, train_10_target = train_test_split(train, train_target, test_size=0.1, stratify=train_target)\n",
    "assert(train_90.shape[0] == train_90_target.shape[0])\n",
    "assert(train_10.shape[0] == train_10_target.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción para el Blending\n",
    "\n",
    "Ahora vamos a realizar una predicción por cada predictor base del 10% separado, utilizando el 90% del set de entrenamiento (separando este 90% en sets de entrenamiento y validacion para optimizar cada modelo). Estas predicciones las vamos a agregar a una copia del set de entrenamiento (*train_blending_predictions*).\n",
    "\n",
    "**Nota**: falta hacer el cross validation con el 90% para encontrar los parámetros óptimos. Actualmento los parámetros están optimizados para el 100%. Esto implica una filtración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_10_with_base_predictions = train_10.copy()\n",
    "for predictor in base_predictors:\n",
    "    train_10_with_base_predictions[predictor.__class__.__name__] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.2 s, sys: 0 ns, total: 45.2 s\n",
      "Wall time: 45.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for predictor in base_predictors:\n",
    "    predictor.fit(train_90, train_90_target) # train\n",
    "    train_10_with_base_predictions[predictor.__class__.__name__] = predictor.predict(train_10) # predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_resolution_height mean</th>\n",
       "      <th>screen_resolution_width mean</th>\n",
       "      <th>screen_resolution_height std</th>\n",
       "      <th>screen_resolution_width std</th>\n",
       "      <th>ad campaign hit</th>\n",
       "      <th>brand listing</th>\n",
       "      <th>checkout</th>\n",
       "      <th>conversion</th>\n",
       "      <th>generic listing</th>\n",
       "      <th>lead</th>\n",
       "      <th>search engine hit</th>\n",
       "      <th>searched products</th>\n",
       "      <th>...</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>madrugada</th>\n",
       "      <th>tarde</th>\n",
       "      <th>maniana</th>\n",
       "      <th>noche</th>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32338d41</th>\n",
       "      <td>640.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.039529</td>\n",
       "      <td>0.002986</td>\n",
       "      <td>0.007181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2a7ac907</th>\n",
       "      <td>1050.0</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.380090</td>\n",
       "      <td>0.178449</td>\n",
       "      <td>0.207158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a73b7e91</th>\n",
       "      <td>667.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.339698</td>\n",
       "      <td>0.080312</td>\n",
       "      <td>0.120180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          screen_resolution_height mean  screen_resolution_width mean  \\\n",
       "person                                                                  \n",
       "32338d41                          640.0                         360.0   \n",
       "2a7ac907                         1050.0                        1680.0   \n",
       "a73b7e91                          667.0                         375.0   \n",
       "\n",
       "          screen_resolution_height std  screen_resolution_width std  \\\n",
       "person                                                                \n",
       "32338d41                           0.0                          0.0   \n",
       "2a7ac907                           0.0                          0.0   \n",
       "a73b7e91                           0.0                          0.0   \n",
       "\n",
       "          ad campaign hit  brand listing  checkout  conversion  \\\n",
       "person                                                           \n",
       "32338d41              0.0            0.0       1.0         0.0   \n",
       "2a7ac907              0.0            0.0       0.0         0.0   \n",
       "a73b7e91              1.0            1.0       0.0         0.0   \n",
       "\n",
       "          generic listing  lead  search engine hit  searched products  \\\n",
       "person                                                                  \n",
       "32338d41              4.0   0.0                4.0                0.0   \n",
       "2a7ac907              1.0   0.0                1.0                0.0   \n",
       "a73b7e91              1.0   0.0                1.0                0.0   \n",
       "\n",
       "                  ...            Saturday  Sunday  Thursday  Tuesday  \\\n",
       "person            ...                                                  \n",
       "32338d41          ...                 0.0     0.0       0.0      0.0   \n",
       "2a7ac907          ...                 0.0     0.0       0.0      0.0   \n",
       "a73b7e91          ...                 0.0     0.0       0.0      0.0   \n",
       "\n",
       "          Wednesday  madrugada  tarde  maniana  noche  AdaBoostRegressor  \\\n",
       "person                                                                     \n",
       "32338d41        0.0          0      0        0      0           0.039529   \n",
       "2a7ac907        0.0          0      0        0      0           0.380090   \n",
       "a73b7e91        0.0          0      0        0      0           0.339698   \n",
       "\n",
       "          RandomForestRegressor  DecisionTreeRegressor  \n",
       "person                                                  \n",
       "32338d41               0.002986               0.007181  \n",
       "2a7ac907               0.178449               0.207158  \n",
       "a73b7e91               0.080312               0.120180  \n",
       "\n",
       "[3 rows x 109 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_10_with_base_predictions.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Blender\n",
    "\n",
    "Entrenamos un modelo blender que use las predicciones de los modelos base (el 10% que separamos) para realizar las predicciones del set de tesing (el que está en kaggle).\n",
    "\n",
    "**Nota**: en este paso podríamos agregar algunos de los features originales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32338d41</th>\n",
       "      <td>0.039529</td>\n",
       "      <td>0.002986</td>\n",
       "      <td>0.007181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2a7ac907</th>\n",
       "      <td>0.380090</td>\n",
       "      <td>0.178449</td>\n",
       "      <td>0.207158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a73b7e91</th>\n",
       "      <td>0.339698</td>\n",
       "      <td>0.080312</td>\n",
       "      <td>0.120180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AdaBoostRegressor  RandomForestRegressor  DecisionTreeRegressor\n",
       "person                                                                   \n",
       "32338d41           0.039529               0.002986               0.007181\n",
       "2a7ac907           0.380090               0.178449               0.207158\n",
       "a73b7e91           0.339698               0.080312               0.120180"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blend_train = train_10_with_base_predictions[[predictor.__class__.__name__ for predictor in base_predictors]]\n",
    "blend_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'solver': 'lbfgs'\n",
    "}\n",
    "blender = LogisticRegression(**param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.863930 (+/- 0.115427)\n",
      "CPU times: user 72 ms, sys: 0 ns, total: 72 ms\n",
      "Wall time: 72.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = cross_val_score(blender, blend_train, train_10_target, cv=10, scoring='roc_auc')\n",
    "print(\"Accuracy: %0.6f (+/- %0.6f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blender.fit(blend_train, train_10_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción del set testing con los modelos base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = labels_to_predict.merge(df_features, how='inner', on='person')\n",
    "assert(testing.shape[0] == labels_to_predict.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_with_base_predictions = testing.copy()\n",
    "for predictor in base_predictors:\n",
    "    testing_with_base_predictions[predictor.__class__.__name__] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.9 s, sys: 12 ms, total: 48.9 s\n",
      "Wall time: 48.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for predictor in base_predictors:\n",
    "    # como warm_start=False cada vez que llamo fit, el modelo se reinicia\n",
    "    predictor.fit(train, train_target) # train\n",
    "    testing_with_base_predictions[predictor.__class__.__name__] = predictor.predict(testing) # predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción del set testing con el blender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4886f805</th>\n",
       "      <td>0.034269</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>0.007434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0297fc1e</th>\n",
       "      <td>0.131195</td>\n",
       "      <td>0.063345</td>\n",
       "      <td>0.039040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2d681dd8</th>\n",
       "      <td>0.034269</td>\n",
       "      <td>0.003577</td>\n",
       "      <td>0.007434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AdaBoostRegressor  RandomForestRegressor  DecisionTreeRegressor\n",
       "person                                                                   \n",
       "4886f805           0.034269               0.002686               0.007434\n",
       "0297fc1e           0.131195               0.063345               0.039040\n",
       "2d681dd8           0.034269               0.003577               0.007434"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_with_base_predictions_for_blender = testing_with_base_predictions[[predictor.__class__.__name__ for predictor in base_predictors]]\n",
    "testing_with_base_predictions_for_blender.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predecimos probabilidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esto es muy específico de logistic reggresion\n",
    "testing_target = pd.DataFrame(data=blender.predict_proba(testing_with_base_predictions_for_blender))[[1]]\n",
    "testing_target.index = testing_with_base_predictions_for_blender.index\n",
    "testing_target.index.name = 'person'\n",
    "testing_target.columns = ['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a probar prediciendo labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_target = pd.DataFrame(data=blender.predict(testing_with_base_predictions_for_blender))\n",
    "testing_target.index = testing_with_base_predictions_for_blender.index\n",
    "testing_target.index.name = 'person'\n",
    "testing_target.columns = ['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# si queremos aplicar blending normal:\n",
    "# testing_target.to_csv(predicciones_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super-set de entrenamiento\n",
    "\n",
    "Juntamos el set de testing y el de entrenamiento en un nuevo super-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_train = train.append(testing)\n",
    "super_train_target = train_target.append(testing_target['label'])\n",
    "assert(super_train.shape[0] == super_train_target.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separación del 10% del super-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ya no puedo usar stratify porque en super_train_target tengo 0, 1 y probabilidades\n",
    "super_train_90, super_train_10, super_train_90_target, super_train_10_target = train_test_split(super_train, super_train_target, test_size=0.1)\n",
    "assert(super_train_90.shape[0] == super_train_90_target.shape[0])\n",
    "assert(super_train_10.shape[0] == super_train_10_target.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción para el super Blending\n",
    "\n",
    "Ahora vamos a realizar una predicción por cada predictor base del 10% separado, utilizando el 90% del super-set de entrenamiento (separando este 90% en sets de entrenamiento y validacion para optimizar cada modelo). Estas predicciones las vamos a agregar a una copia del set de entrenamiento (*super_train_blending_predictions*).\n",
    "\n",
    "**Nota**: falta hacer el cross validation con el 90% para encontrar los parámetros óptimos. Actualmento los parámetros están optimizados para el 100% del set de entrenamiento original. Esto implica una filtración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_train_10_with_base_predictions = super_train_10.copy()\n",
    "for predictor in base_predictors:\n",
    "    super_train_10_with_base_predictions[predictor.__class__.__name__] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 41s, sys: 184 ms, total: 1min 41s\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for predictor in base_predictors:\n",
    "    predictor.fit(super_train_90, super_train_90_target) # train\n",
    "    super_train_10_with_base_predictions[predictor.__class__.__name__] = predictor.predict(super_train_10) # predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Blender con el super-set\n",
    "\n",
    "Necesitamos un modelo en el cual los targets puedan ser floats, por eso no usamos LogisticRegression. En este caso decidimos utilizar xgboost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a080af28</th>\n",
       "      <td>0.026998</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>0.005339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2b8380d4</th>\n",
       "      <td>0.031209</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>0.005339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02e59a44</th>\n",
       "      <td>0.313442</td>\n",
       "      <td>0.077051</td>\n",
       "      <td>0.057854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AdaBoostRegressor  RandomForestRegressor  DecisionTreeRegressor\n",
       "person                                                                   \n",
       "a080af28           0.026998               0.001572               0.005339\n",
       "2b8380d4           0.031209               0.005910               0.005339\n",
       "02e59a44           0.313442               0.077051               0.057854"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_blend_train = super_train_10_with_base_predictions[[predictor.__class__.__name__ for predictor in base_predictors]]\n",
    "super_blend_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "#     'n_estimators': 'lbfgs'\n",
    "    'solver': 'lbfgs'\n",
    "}\n",
    "super_blender = LogisticRegression(**param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.850215 (+/- 0.074442)\n",
      "CPU times: user 452 ms, sys: 640 ms, total: 1.09 s\n",
      "Wall time: 317 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = cross_val_score(super_blender, super_blend_train, super_train_10_target, cv=10, scoring='roc_auc')\n",
    "print(\"Accuracy: %0.6f (+/- %0.6f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_blender.fit(super_blend_train, super_train_10_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción del set de testing con los modelos base entrenados con el super-set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_testing_with_base_predictions = testing.copy()\n",
    "for predictor in base_predictors:\n",
    "    super_testing_with_base_predictions[predictor.__class__.__name__] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 48s, sys: 108 ms, total: 1min 48s\n",
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for predictor in base_predictors:\n",
    "    # como warm_start=False cada vez que llamo fit, el modelo se reinicia\n",
    "    predictor.fit(super_train, super_train_target) # train\n",
    "    super_testing_with_base_predictions[predictor.__class__.__name__] = predictor.predict(testing) # predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción del set testing con el super blender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4886f805</th>\n",
       "      <td>0.028806</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>0.003917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0297fc1e</th>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.029293</td>\n",
       "      <td>0.023855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2d681dd8</th>\n",
       "      <td>0.028806</td>\n",
       "      <td>0.002275</td>\n",
       "      <td>0.003917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AdaBoostRegressor  RandomForestRegressor  DecisionTreeRegressor\n",
       "person                                                                   \n",
       "4886f805           0.028806               0.001707               0.003917\n",
       "0297fc1e           0.114583               0.029293               0.023855\n",
       "2d681dd8           0.028806               0.002275               0.003917"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_with_base_predictions_for_super_blender = super_testing_with_base_predictions[[predictor.__class__.__name__ for predictor in base_predictors]]\n",
    "testing_with_base_predictions_for_super_blender.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4886f805</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0297fc1e</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2d681dd8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          label\n",
       "person         \n",
       "4886f805      0\n",
       "0297fc1e      0\n",
       "2d681dd8      0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = super_blender.predict(testing_with_base_predictions_for_super_blender)\n",
    "predictions = pd.DataFrame(data=predictions, index=testing_with_base_predictions_for_super_blender.index)\n",
    "predictions.columns = ['label']\n",
    "predictions.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions.to_csv(predicciones_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blending ensembling\n",
    " - [Predictores base](#Predictores-base)\n",
    " - [Separación del 10%](#Separación-del-10%)\n",
    " - [Predicción para el Blending](#Predicción-para-el-Blending)\n",
    " - [Modelo Blender](#Modelo-Blender)\n",
    " - [Predicción del set testing con los modelos base](#Predicción-del-set-testing-con-los-modelos-base)\n",
    " - [Predicción del set testing con el blender](#Predicción-del-set-testing-con-el-blender)\n",
    "\n",
    "Repito con un super set de entrenamiento:\n",
    "\n",
    " - [Super set de entrenamiento](#Super-set-de-entrenamiento)\n",
    " - [Separación del 10% del super-set](#Separación-del-10%-del-super-set)\n",
    " - [Predicción para el super Blending](#Predicción-para-el-super-Blending)\n",
    " - [Modelo Blender con el super-set](#Modelo-Blender-con-el-super-set)\n",
    " - [Predicción del set de testing con los modelos base entrenados con el super-set de entrenamiento](#Predicción-del-set-de-testing-con-los-modelos-base-entrenados-con-el-super-set-de-entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBRegressor\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '__file__' in locals():\n",
    "    current_folder = os.path.dirname(os.path.abspath(__file__))\n",
    "else:\n",
    "    current_folder = os.getcwd()\n",
    "\n",
    "set_de_entrenamiento_testing_y_prediccion = '\"{}\"'.format(os.path.join(\n",
    "    current_folder,\n",
    "    '..',\n",
    "    'Set de entrenamiento, testing y predicción.ipynb'\n",
    "))\n",
    "merge_features = '\"{}\"'.format(os.path.join(current_folder, '..', 'Features', 'Merge features.ipynb'))\n",
    "predicciones_csv = os.path.join(current_folder, '..', 'predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargo el df con los features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "La limpieza ya corrió en este Kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/GitHub/7506-datos-tp2/Features/../Limpieza.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'limpieza_runned'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'La limpieza ya corrió en este Kernel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlimpieza_runned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: La limpieza ya corrió en este Kernel"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "La limpieza ya corrió en este Kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/GitHub/7506-datos-tp2/Features/../Limpieza.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'limpieza_runned'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'La limpieza ya corrió en este Kernel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlimpieza_runned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: La limpieza ya corrió en este Kernel"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "La limpieza ya corrió en este Kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/GitHub/7506-datos-tp2/Features/../Limpieza.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'limpieza_runned'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'La limpieza ya corrió en este Kernel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlimpieza_runned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: La limpieza ya corrió en este Kernel"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "%run $merge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(df_features.shape[0] == get_clean_df()['person'].unique().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargo el set de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run $set_de_entrenamiento_testing_y_prediccion\n",
    "\n",
    "labels_with_features = labels.merge(df_features, how='inner', on='person')\n",
    "train = labels_with_features.drop('label', axis=1)\n",
    "train_target = labels_with_features['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictores base\n",
    "\n",
    "En esta sección vamos a preparar los predictores base a utilizar. Estos son los mismos que se encuentran en la carpeta *Algoritmos de ML*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_predictors = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'n_estimators': 128,\n",
    "    'loss': 'linear',\n",
    "    'learning_rate': 0.07,\n",
    "    'base_estimator': DecisionTreeRegressor(criterion='mse', max_depth=4, max_features=None,\n",
    "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "            min_impurity_split=None, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            presort=False, random_state=None, splitter='best')\n",
    "}\n",
    "\n",
    "base_predictors.append(AdaBoostRegressor(**param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'bootstrap': True,\n",
    "    'max_depth': 10,\n",
    "    'max_features': 81,\n",
    "    'min_samples_leaf': 49,\n",
    "    'min_samples_split': 8,\n",
    "    'n_estimators': 56\n",
    "}\n",
    "\n",
    "base_predictors.append(RandomForestRegressor(**param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_predictors.append(DecisionTreeRegressor(criterion='mse', max_depth=4, max_features=None,\n",
    "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "            min_impurity_split=None, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            presort=False, random_state=None, splitter='best'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'objective': 'reg:logistic',\n",
    "    'colsample_bylevel': 0.6605668347627213,\n",
    "    'colsample_bytree': 0.5279014819087092,\n",
    "    'min_child_weight': 4.302125582335056,\n",
    "    'learning_rate': 0.15803667962605694,\n",
    "    'max_delta_step': 7.592652591386328,\n",
    "    'n_estimators': 65,\n",
    "    'reg_lambda': 1.1181195507921775,\n",
    "    'max_depth': 9,\n",
    "    'silent': True,\n",
    "    'subsample': 0.43744176565530823,\n",
    "    'reg_alpha': 3.845311207046479,\n",
    "    'gamma': 6.219264874528072\n",
    "}\n",
    "\n",
    "base_predictors.append(XGBRegressor(**param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separación del 10%\n",
    "\n",
    "Separo un 10% del set de entrenamiento para luego entrenar el blending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_90, train_10, train_90_target, train_10_target = train_test_split(train, train_target, test_size=0.1, stratify=train_target)\n",
    "assert(train_90.shape[0] == train_90_target.shape[0])\n",
    "assert(train_10.shape[0] == train_10_target.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción para el Blending\n",
    "\n",
    "Ahora vamos a realizar una predicción por cada predictor base del 10% separado, utilizando el 90% del set de entrenamiento (separando este 90% en sets de entrenamiento y validacion para optimizar cada modelo). Estas predicciones las vamos a agregar a una copia del set de entrenamiento (*train_blending_predictions*).\n",
    "\n",
    "**Nota**: falta hacer el cross validation con el 90% para encontrar los parámetros óptimos. Actualmento los parámetros están optimizados para el 100%. Esto implica una filtración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_10_with_base_predictions = train_10.copy()\n",
    "for predictor in base_predictors:\n",
    "    train_10_with_base_predictions[predictor.__class__.__name__] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "CPU times: user 44.2 s, sys: 52 ms, total: 44.3 s\n",
      "Wall time: 1min 59s\n"
=======
      "CPU times: user 45.9 s, sys: 82.1 ms, total: 45.9 s\n",
      "Wall time: 46 s\n"
>>>>>>> origin/master
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for predictor in base_predictors:\n",
    "    predictor.fit(train_90, train_90_target) # train\n",
    "    train_10_with_base_predictions[predictor.__class__.__name__] = predictor.predict(train_10) # predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_resolution_height mean</th>\n",
       "      <th>screen_resolution_width mean</th>\n",
       "      <th>screen_resolution_height std</th>\n",
       "      <th>screen_resolution_width std</th>\n",
       "      <th>ad campaign hit</th>\n",
       "      <th>brand listing</th>\n",
       "      <th>checkout</th>\n",
       "      <th>conversion</th>\n",
       "      <th>generic listing</th>\n",
       "      <th>lead</th>\n",
       "      <th>search engine hit</th>\n",
       "      <th>searched products</th>\n",
       "      <th>...</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
<<<<<<< HEAD
       "      <th>tarde</th>\n",
=======
>>>>>>> origin/master
       "      <th>madrugada</th>\n",
       "      <th>maniana</th>\n",
       "      <th>tarde</th>\n",
       "      <th>noche</th>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <th>XGBRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
<<<<<<< HEAD
       "      <th>fcb5fb33</th>\n",
       "      <td>480.0</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
=======
       "      <th>2e65d3b5</th>\n",
       "      <td>768.00000</td>\n",
       "      <td>1366.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
>>>>>>> origin/master
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
<<<<<<< HEAD
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
=======
       "      <td>6.0</td>\n",
>>>>>>> origin/master
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
<<<<<<< HEAD
       "      <td>0</td>\n",
=======
>>>>>>> origin/master
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
<<<<<<< HEAD
       "      <td>0.058259</td>\n",
       "      <td>0.006396</td>\n",
       "      <td>0.008419</td>\n",
       "      <td>0.011864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51fdbb43</th>\n",
       "      <td>900.0</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
=======
       "      <td>0.421945</td>\n",
       "      <td>0.326855</td>\n",
       "      <td>0.433735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6584f328</th>\n",
       "      <td>640.00000</td>\n",
       "      <td>360.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
>>>>>>> origin/master
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
<<<<<<< HEAD
       "      <td>0</td>\n",
       "      <td>0.038176</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.008419</td>\n",
       "      <td>0.006298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177bc00b</th>\n",
       "      <td>768.0</td>\n",
       "      <td>1109.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147.801669</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
=======
       "      <td>0.043179</td>\n",
       "      <td>0.005145</td>\n",
       "      <td>0.006621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68e3709c</th>\n",
       "      <td>629.62963</td>\n",
       "      <td>370.37037</td>\n",
       "      <td>53.886025</td>\n",
       "      <td>53.886025</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
>>>>>>> origin/master
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
<<<<<<< HEAD
       "      <td>0.447653</td>\n",
       "      <td>0.324053</td>\n",
       "      <td>0.212080</td>\n",
       "      <td>0.259470</td>\n",
=======
       "      <td>0.148983</td>\n",
       "      <td>0.031703</td>\n",
       "      <td>0.040455</td>\n",
>>>>>>> origin/master
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          screen_resolution_height mean  screen_resolution_width mean  \\\n",
       "person                                                                  \n",
<<<<<<< HEAD
       "fcb5fb33                          480.0                    320.000000   \n",
       "51fdbb43                          900.0                   1600.000000   \n",
       "177bc00b                          768.0                   1109.333333   \n",
       "\n",
       "          screen_resolution_height std  screen_resolution_width std  \\\n",
       "person                                                                \n",
       "fcb5fb33                           0.0                     0.000000   \n",
       "51fdbb43                           0.0                     0.000000   \n",
       "177bc00b                           0.0                   147.801669   \n",
       "\n",
       "          ad campaign hit  brand listing  checkout  conversion  \\\n",
       "person                                                           \n",
       "fcb5fb33              0.0            0.0       1.0         0.0   \n",
       "51fdbb43              3.0            0.0       1.0         0.0   \n",
       "177bc00b              8.0           15.0       3.0         0.0   \n",
       "\n",
       "          generic listing  lead  search engine hit  searched products  \\\n",
       "person                                                                  \n",
       "fcb5fb33              5.0   0.0                0.0                2.0   \n",
       "51fdbb43              0.0   0.0                0.0                0.0   \n",
       "177bc00b              1.0   0.0                2.0                0.0   \n",
       "\n",
       "              ...       Sunday  Thursday  Tuesday  Wednesday  tarde  \\\n",
       "person        ...                                                     \n",
       "fcb5fb33      ...          0.0       0.0      0.0        0.0      0   \n",
       "51fdbb43      ...          0.0       0.0      0.0        0.0      0   \n",
       "177bc00b      ...          0.0       0.0      0.0        0.0      0   \n",
       "\n",
       "          madrugada  maniana  noche  AdaBoostRegressor  RandomForestRegressor  \\\n",
       "person                                                                          \n",
       "fcb5fb33          0        0      0           0.058259               0.006396   \n",
       "51fdbb43          0        0      0           0.038176               0.001690   \n",
       "177bc00b          0        0      0           0.447653               0.324053   \n",
       "\n",
       "          DecisionTreeRegressor  XGBRegressor  \n",
       "person                                         \n",
       "fcb5fb33               0.008419      0.011864  \n",
       "51fdbb43               0.008419      0.006298  \n",
       "177bc00b               0.212080      0.259470  \n",
=======
       "2e65d3b5                      768.00000                    1366.00000   \n",
       "6584f328                      640.00000                     360.00000   \n",
       "68e3709c                      629.62963                     370.37037   \n",
       "\n",
       "          screen_resolution_height std  screen_resolution_width std  \\\n",
       "person                                                                \n",
       "2e65d3b5                      0.000000                     0.000000   \n",
       "6584f328                      0.000000                     0.000000   \n",
       "68e3709c                     53.886025                    53.886025   \n",
       "\n",
       "          ad campaign hit  brand listing  checkout  conversion  \\\n",
       "person                                                           \n",
       "2e65d3b5              5.0           12.0       1.0         1.0   \n",
       "6584f328              6.0            6.0       1.0         1.0   \n",
       "68e3709c              3.0            4.0       3.0         0.0   \n",
       "\n",
       "          generic listing  lead  search engine hit  searched products  \\\n",
       "person                                                                  \n",
       "2e65d3b5              6.0   0.0                6.0                0.0   \n",
       "6584f328              0.0   0.0                0.0                0.0   \n",
       "68e3709c             19.0   0.0               12.0               29.0   \n",
       "\n",
       "                  ...            Saturday  Sunday  Thursday  Tuesday  \\\n",
       "person            ...                                                  \n",
       "2e65d3b5          ...                 0.0     0.0       0.0      1.0   \n",
       "6584f328          ...                 0.0     0.0       0.0      0.0   \n",
       "68e3709c          ...                 0.0     0.0       0.0      0.0   \n",
       "\n",
       "          Wednesday  madrugada  maniana  tarde  noche  AdaBoostRegressor  \\\n",
       "person                                                                     \n",
       "2e65d3b5        0.0          0        0      1      0           0.421945   \n",
       "6584f328        0.0          0        0      1      0           0.043179   \n",
       "68e3709c        0.0          0        0      0      0           0.148983   \n",
       "\n",
       "          RandomForestRegressor  DecisionTreeRegressor  \n",
       "person                                                  \n",
       "2e65d3b5               0.326855               0.433735  \n",
       "6584f328               0.005145               0.006621  \n",
       "68e3709c               0.031703               0.040455  \n",
>>>>>>> origin/master
       "\n",
       "[3 rows x 132 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_10_with_base_predictions.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Blender\n",
    "\n",
    "Entrenamos un modelo blender que use las predicciones de los modelos base (el 10% que separamos) para realizar las predicciones del set de tesing (el que está en kaggle).\n",
    "\n",
    "**Nota**: en este paso podríamos agregar algunos de los features originales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <th>XGBRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
<<<<<<< HEAD
       "      <th>fcb5fb33</th>\n",
       "      <td>0.058259</td>\n",
       "      <td>0.006396</td>\n",
       "      <td>0.008419</td>\n",
       "      <td>0.011864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51fdbb43</th>\n",
       "      <td>0.038176</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.008419</td>\n",
       "      <td>0.006298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177bc00b</th>\n",
       "      <td>0.447653</td>\n",
       "      <td>0.324053</td>\n",
       "      <td>0.212080</td>\n",
       "      <td>0.259470</td>\n",
=======
       "      <th>2e65d3b5</th>\n",
       "      <td>0.421945</td>\n",
       "      <td>0.326855</td>\n",
       "      <td>0.433735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6584f328</th>\n",
       "      <td>0.043179</td>\n",
       "      <td>0.005145</td>\n",
       "      <td>0.006621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68e3709c</th>\n",
       "      <td>0.148983</td>\n",
       "      <td>0.031703</td>\n",
       "      <td>0.040455</td>\n",
>>>>>>> origin/master
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "          AdaBoostRegressor  RandomForestRegressor  DecisionTreeRegressor  \\\n",
       "person                                                                      \n",
       "fcb5fb33           0.058259               0.006396               0.008419   \n",
       "51fdbb43           0.038176               0.001690               0.008419   \n",
       "177bc00b           0.447653               0.324053               0.212080   \n",
       "\n",
       "          XGBRegressor  \n",
       "person                  \n",
       "fcb5fb33      0.011864  \n",
       "51fdbb43      0.006298  \n",
       "177bc00b      0.259470  "
=======
       "          AdaBoostRegressor  RandomForestRegressor  DecisionTreeRegressor\n",
       "person                                                                   \n",
       "2e65d3b5           0.421945               0.326855               0.433735\n",
       "6584f328           0.043179               0.005145               0.006621\n",
       "68e3709c           0.148983               0.031703               0.040455"
>>>>>>> origin/master
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blend_train = train_10_with_base_predictions[[predictor.__class__.__name__ for predictor in base_predictors]]\n",
    "blend_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'solver': 'lbfgs'\n",
    "}\n",
    "blender = LogisticRegression(**param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Accuracy: 0.858502 (+/- 0.123263)\n",
      "CPU times: user 144 ms, sys: 0 ns, total: 144 ms\n",
      "Wall time: 360 ms\n"
=======
      "Accuracy: 0.871463 (+/- 0.077773)\n",
      "CPU times: user 156 ms, sys: 20.7 ms, total: 177 ms\n",
      "Wall time: 207 ms\n"
>>>>>>> origin/master
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = cross_val_score(blender, blend_train, train_10_target, cv=10, scoring='roc_auc')\n",
    "print(\"Accuracy: %0.6f (+/- %0.6f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blender.fit(blend_train, train_10_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción del set testing con los modelos base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = labels_to_predict.merge(df_features, how='inner', on='person')\n",
    "assert(testing.shape[0] == labels_to_predict.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_with_base_predictions = testing.copy()\n",
    "for predictor in base_predictors:\n",
    "    testing_with_base_predictions[predictor.__class__.__name__] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.3 s, sys: 133 ms, total: 53.5 s\n",
      "Wall time: 53.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for predictor in base_predictors:\n",
    "    # como warm_start=False cada vez que llamo fit, el modelo se reinicia\n",
    "    predictor.fit(train, train_target) # train\n",
    "    testing_with_base_predictions[predictor.__class__.__name__] = predictor.predict(testing) # predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción del set testing con el blender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4886f805</th>\n",
       "      <td>0.038229</td>\n",
       "      <td>0.002735</td>\n",
       "      <td>0.007434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0297fc1e</th>\n",
       "      <td>0.143778</td>\n",
       "      <td>0.064331</td>\n",
       "      <td>0.039040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2d681dd8</th>\n",
       "      <td>0.038229</td>\n",
       "      <td>0.004466</td>\n",
       "      <td>0.007434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AdaBoostRegressor  RandomForestRegressor  DecisionTreeRegressor\n",
       "person                                                                   \n",
       "4886f805           0.038229               0.002735               0.007434\n",
       "0297fc1e           0.143778               0.064331               0.039040\n",
       "2d681dd8           0.038229               0.004466               0.007434"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_with_base_predictions_for_blender = testing_with_base_predictions[[predictor.__class__.__name__ for predictor in base_predictors]]\n",
    "testing_with_base_predictions_for_blender.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predecimos probabilidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esto es muy específico de logistic reggresion\n",
    "testing_target = pd.DataFrame(data=blender.predict_proba(testing_with_base_predictions_for_blender))[[1]]\n",
    "testing_target.index = testing_with_base_predictions_for_blender.index\n",
    "testing_target.index.name = 'person'\n",
    "testing_target.columns = ['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a probar prediciendo labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_target = pd.DataFrame(data=blender.predict(testing_with_base_predictions_for_blender))\n",
    "testing_target.index = testing_with_base_predictions_for_blender.index\n",
    "testing_target.index.name = 'person'\n",
    "testing_target.columns = ['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# si queremos aplicar blending normal:\n",
    "# testing_target.to_csv(predicciones_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super-set de entrenamiento\n",
    "\n",
    "Juntamos el set de testing y el de entrenamiento en un nuevo super-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_train = train.append(testing)\n",
    "super_train_target = train_target.append(testing_target['label'])\n",
    "assert(super_train.shape[0] == super_train_target.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separación del 10% del super-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ya no puedo usar stratify porque en super_train_target tengo 0, 1 y probabilidades\n",
    "super_train_90, super_train_10, super_train_90_target, super_train_10_target = train_test_split(super_train, super_train_target, test_size=0.1)\n",
    "assert(super_train_90.shape[0] == super_train_90_target.shape[0])\n",
    "assert(super_train_10.shape[0] == super_train_10_target.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción para el super Blending\n",
    "\n",
    "Ahora vamos a realizar una predicción por cada predictor base del 10% separado, utilizando el 90% del super-set de entrenamiento (separando este 90% en sets de entrenamiento y validacion para optimizar cada modelo). Estas predicciones las vamos a agregar a una copia del set de entrenamiento (*super_train_blending_predictions*).\n",
    "\n",
    "**Nota**: falta hacer el cross validation con el 90% para encontrar los parámetros óptimos. Actualmento los parámetros están optimizados para el 100% del set de entrenamiento original. Esto implica una filtración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_train_10_with_base_predictions = super_train_10.copy()\n",
    "for predictor in base_predictors:\n",
    "    super_train_10_with_base_predictions[predictor.__class__.__name__] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 56s, sys: 280 ms, total: 1min 56s\n",
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for predictor in base_predictors:\n",
    "    predictor.fit(super_train_90, super_train_90_target) # train\n",
    "    super_train_10_with_base_predictions[predictor.__class__.__name__] = predictor.predict(super_train_10) # predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Blender con el super-set\n",
    "\n",
    "Necesitamos un modelo en el cual los targets puedan ser floats, por eso no usamos LogisticRegression. En este caso decidimos utilizar xgboost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a8d906b0</th>\n",
       "      <td>0.409028</td>\n",
       "      <td>0.167797</td>\n",
       "      <td>0.102187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42316be2</th>\n",
       "      <td>0.029734</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>0.004667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37135eae</th>\n",
       "      <td>0.063227</td>\n",
       "      <td>0.006322</td>\n",
       "      <td>0.004667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AdaBoostRegressor  RandomForestRegressor  DecisionTreeRegressor\n",
       "person                                                                   \n",
       "a8d906b0           0.409028               0.167797               0.102187\n",
       "42316be2           0.029734               0.001610               0.004667\n",
       "37135eae           0.063227               0.006322               0.004667"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_blend_train = super_train_10_with_base_predictions[[predictor.__class__.__name__ for predictor in base_predictors]]\n",
    "super_blend_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "#     'n_estimators': 'lbfgs'\n",
    "    'solver': 'lbfgs'\n",
    "}\n",
    "super_blender = LogisticRegression(**param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.872336 (+/- 0.096028)\n",
      "CPU times: user 370 ms, sys: 50 ms, total: 420 ms\n",
      "Wall time: 112 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = cross_val_score(super_blender, super_blend_train, super_train_10_target, cv=10, scoring='roc_auc')\n",
    "print(\"Accuracy: %0.6f (+/- %0.6f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_blender.fit(super_blend_train, super_train_10_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción del set de testing con los modelos base entrenados con el super-set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_testing_with_base_predictions = testing.copy()\n",
    "for predictor in base_predictors:\n",
    "    super_testing_with_base_predictions[predictor.__class__.__name__] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 7s, sys: 365 ms, total: 2min 7s\n",
      "Wall time: 2min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for predictor in base_predictors:\n",
    "    # como warm_start=False cada vez que llamo fit, el modelo se reinicia\n",
    "    predictor.fit(super_train, super_train_target) # train\n",
    "    super_testing_with_base_predictions[predictor.__class__.__name__] = predictor.predict(testing) # predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción del set testing con el super blender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4886f805</th>\n",
       "      <td>0.031315</td>\n",
       "      <td>0.001652</td>\n",
       "      <td>0.003917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0297fc1e</th>\n",
       "      <td>0.140220</td>\n",
       "      <td>0.028422</td>\n",
       "      <td>0.023855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2d681dd8</th>\n",
       "      <td>0.031315</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>0.003917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AdaBoostRegressor  RandomForestRegressor  DecisionTreeRegressor\n",
       "person                                                                   \n",
       "4886f805           0.031315               0.001652               0.003917\n",
       "0297fc1e           0.140220               0.028422               0.023855\n",
       "2d681dd8           0.031315               0.002166               0.003917"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_with_base_predictions_for_super_blender = super_testing_with_base_predictions[[predictor.__class__.__name__ for predictor in base_predictors]]\n",
    "testing_with_base_predictions_for_super_blender.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4886f805</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0297fc1e</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2d681dd8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          label\n",
       "person         \n",
       "4886f805      0\n",
       "0297fc1e      0\n",
       "2d681dd8      0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = super_blender.predict(testing_with_base_predictions_for_super_blender)\n",
    "predictions = pd.DataFrame(data=predictions, index=testing_with_base_predictions_for_super_blender.index)\n",
    "predictions.columns = ['label']\n",
    "predictions.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions.to_csv(predicciones_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3077\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3078\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: False",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-1f721031b4aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: False"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.view of person\n",
       "4886f805    True\n",
       "0297fc1e    True\n",
       "2d681dd8    True\n",
       "cccea85e    True\n",
       "4c8a8b93    True\n",
       "29ebb414    True\n",
       "3dc1950f    True\n",
       "8ea4c165    True\n",
       "d8cfe234    True\n",
       "d6bc64df    True\n",
       "ec9c4059    True\n",
       "d21b8e6b    True\n",
       "2a724d87    True\n",
       "686c49c9    True\n",
       "a08d42ea    True\n",
       "c98f5cf1    True\n",
       "d614c608    True\n",
       "e45acd53    True\n",
       "7d876393    True\n",
       "f5af843f    True\n",
       "5a724794    True\n",
       "00091926    True\n",
       "55d1e0ee    True\n",
       "f87be219    True\n",
       "49c19e32    True\n",
       "bb78c182    True\n",
       "e2bfe05f    True\n",
       "0e9d0ae2    True\n",
       "cb68850c    True\n",
       "f30ef764    True\n",
       "            ... \n",
       "523c7e69    True\n",
       "d2e564cb    True\n",
       "eb27e544    True\n",
       "b32e7113    True\n",
       "a65f2cf0    True\n",
       "a70b9f00    True\n",
       "a161fd76    True\n",
       "e9a4d3a8    True\n",
       "24f53ba2    True\n",
       "39cf8fa0    True\n",
       "9ceab28a    True\n",
       "f85da107    True\n",
       "154d2935    True\n",
       "3adf7ca4    True\n",
       "2e89874a    True\n",
       "ef4e52ab    True\n",
       "85e0f62a    True\n",
       "2c209f87    True\n",
       "4ddb8c19    True\n",
       "25bd8078    True\n",
       "87d306fc    True\n",
       "a2b1e355    True\n",
       "fb88a7ea    True\n",
       "9707cd0e    True\n",
       "6f7632db    True\n",
       "a1c2a901    True\n",
       "ed3f80d7    True\n",
       "92f2d94b    True\n",
       "40bf23ab    True\n",
       "80aea0a0    True\n",
       "Name: label, Length: 19415, dtype: bool>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

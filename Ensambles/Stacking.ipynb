{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking ensembling\n",
    "\n",
    "Vamos a crear un ensamble de tipo stacking. Para ello se utilizaron las siguientes fuentes:\n",
    " - https://mlwave.com/kaggle-ensembling-guide/\n",
    " - http://blog.kaggle.com/2016/12/27/a-kagglers-guide-to-model-stacking-in-practice/\n",
    " - https://github.com/emanuele/kaggle_pbr/blob/master/blend.py\n",
    "\n",
    "Para ello se desarrollaron las siguientes secciones:\n",
    " - [Predictores base](#Predictores-base)\n",
    "     - [Xgboost](#Xgboost)\n",
    "     - [Random Forest](#Random-Forest)\n",
    "     - [AdaBoost](#AdaBoost)\n",
    " - [Metafeatures](#Metafeatures)\n",
    " - [Predictor Stacking](#Predictor-Stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBRegressor\n",
    "from time import time\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '__file__' in locals():\n",
    "    current_folder = os.path.dirname(os.path.abspath(__file__))\n",
    "else:\n",
    "    current_folder = os.getcwd()\n",
    "\n",
    "set_de_entrenamiento_testing_y_prediccion = '\"{}\"'.format(os.path.join(\n",
    "    current_folder,\n",
    "    '..',\n",
    "    'Set de entrenamiento, testing y predicción.ipynb'\n",
    "))\n",
    "merge_features = '\"{}\"'.format(os.path.join(current_folder, '..', 'Features', 'Merge features.ipynb'))\n",
    "predicciones_csv = os.path.join(current_folder, '..', 'predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargo el df con los features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "La limpieza ya corrió en este Kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/DATOS/Datos/tp2/Features/../Limpieza.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'limpieza_runned'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'La limpieza ya corrió en este Kernel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlimpieza_runned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: La limpieza ya corrió en este Kernel"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "La limpieza ya corrió en este Kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/DATOS/Datos/tp2/Features/../Limpieza.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'limpieza_runned'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'La limpieza ya corrió en este Kernel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlimpieza_runned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: La limpieza ya corrió en este Kernel"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "La limpieza ya corrió en este Kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/DATOS/Datos/tp2/Features/../Limpieza.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'limpieza_runned'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'La limpieza ya corrió en este Kernel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlimpieza_runned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: La limpieza ya corrió en este Kernel"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "%run $merge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(df_features.shape[0] == get_clean_df()['person'].unique().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargo el set de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run $set_de_entrenamiento_testing_y_prediccion\n",
    "\n",
    "labels_with_features = labels.merge(df_features, how='inner', on='person')\n",
    "train = labels_with_features.drop('label', axis=1)\n",
    "train_target = labels_with_features['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictores base\n",
    "\n",
    "En esta sección vamos a preparar los predictores base a utilizar. Estos son los mismos que se encuentran en la carpeta *Algoritmos de ML*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_predictors = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Xgboost\n",
    "\n",
    "Nota: vamos a usar XGBRegressor para tener la misma interfaz con el resto de los predictores. Los hiperparámetros tienen distinto nombre, pero producen los mismos resultados. Se puede consultar la documentación de xgboost para encontrar los nombres de los parámetros: https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBRegressor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'objective': 'reg:logistic',\n",
    "    'colsamble_bylevel': 1,\n",
    "    'colsamble_bytree': 1,\n",
    "    'min_child_weight': 1,\n",
    "    'learning_rate': 0.3,\n",
    "    'max_delta_step': 5,\n",
    "    'n_estimators': 25,\n",
    "    'reg_lambda': 3,\n",
    "    'max_depth': 9,\n",
    "    'silent': True,\n",
    "    'subsample': 1,\n",
    "    'reg_alpha': 2,\n",
    "    'gamma': 10\n",
    "}\n",
    "\n",
    "base_predictors.append(XGBRegressor(**param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'bootstrap': True,\n",
    "    'max_depth': 9,\n",
    "    'max_features': 37,\n",
    "    'min_samples_leaf': 30,\n",
    "    'min_samples_split': 7,\n",
    "    'n_estimators': 784\n",
    "}\n",
    "\n",
    "base_predictors.append(RandomForestRegressor(**param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'n_estimators': 124,\n",
    "    'loss': 'linear',\n",
    "    'learning_rate': 0.07,\n",
    "    'base_estimator': DecisionTreeRegressor(criterion='mse', max_depth=4, max_features=None,\n",
    "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "            min_impurity_split=None, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            presort=False, random_state=None, splitter='best')\n",
    "}\n",
    "\n",
    "base_predictors.append(AdaBoostRegressor(**param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metafeatures\n",
    "\n",
    "Ahora vamos a realizar una predicción por cada predictor base, y las vamos a agregar a una copia del set de entrenamiento (*train_meta*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta = train.copy()\n",
    "for predictor in base_predictors:\n",
    "    train_meta[predictor.__class__.__name__] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar las predicciones utilizar cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 12s, sys: 56 ms, total: 13min 12s\n",
      "Wall time: 13min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kf = KFold(n_splits=10, shuffle=False)\n",
    "for train_i, validation_i in kf.split(train):    \n",
    "    for predictor in base_predictors:\n",
    "        # como warm_start=False cada vez que llamo fit, el modelo se reinicia\n",
    "        predictor.fit(train.iloc[train_i], train_target.iloc[train_i]) # train\n",
    "        train_meta[predictor.__class__.__name__].iloc[validation_i] = predictor.predict(train.iloc[validation_i]) # predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_resolution_height mean</th>\n",
       "      <th>screen_resolution_width mean</th>\n",
       "      <th>screen_resolution_height std</th>\n",
       "      <th>screen_resolution_width std</th>\n",
       "      <th>ad campaign hit</th>\n",
       "      <th>brand listing</th>\n",
       "      <th>checkout</th>\n",
       "      <th>conversion</th>\n",
       "      <th>generic listing</th>\n",
       "      <th>lead</th>\n",
       "      <th>search engine hit</th>\n",
       "      <th>searched products</th>\n",
       "      <th>...</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>madrugada</th>\n",
       "      <th>tarde</th>\n",
       "      <th>noche</th>\n",
       "      <th>maniana</th>\n",
       "      <th>XGBRegressor</th>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0566e9c1</th>\n",
       "      <td>568.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016541</td>\n",
       "      <td>0.020955</td>\n",
       "      <td>0.116183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6ec7ee77</th>\n",
       "      <td>640.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100654</td>\n",
       "      <td>0.078044</td>\n",
       "      <td>0.293405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abe7a2fb</th>\n",
       "      <td>640.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010634</td>\n",
       "      <td>0.025350</td>\n",
       "      <td>0.165819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          screen_resolution_height mean  screen_resolution_width mean  \\\n",
       "person                                                                  \n",
       "0566e9c1                          568.0                         320.0   \n",
       "6ec7ee77                          640.0                         360.0   \n",
       "abe7a2fb                          640.0                         360.0   \n",
       "\n",
       "          screen_resolution_height std  screen_resolution_width std  \\\n",
       "person                                                                \n",
       "0566e9c1                           0.0                          0.0   \n",
       "6ec7ee77                           0.0                          0.0   \n",
       "abe7a2fb                           0.0                          0.0   \n",
       "\n",
       "          ad campaign hit  brand listing  checkout  conversion  \\\n",
       "person                                                           \n",
       "0566e9c1              6.0            3.0       1.0         1.0   \n",
       "6ec7ee77              1.0            0.0       0.0         0.0   \n",
       "abe7a2fb              9.0           14.0       1.0         0.0   \n",
       "\n",
       "          generic listing  lead  search engine hit  searched products  \\\n",
       "person                                                                  \n",
       "0566e9c1             15.0   0.0                1.0                0.0   \n",
       "6ec7ee77              0.0   0.0                0.0                0.0   \n",
       "abe7a2fb              9.0   0.0                4.0                6.0   \n",
       "\n",
       "                ...          Saturday  Sunday  Thursday  Tuesday  Wednesday  \\\n",
       "person          ...                                                           \n",
       "0566e9c1        ...               0.0     0.0       0.0      0.0        1.0   \n",
       "6ec7ee77        ...               0.0     0.0       0.0      0.0        0.0   \n",
       "abe7a2fb        ...               0.0     0.0       0.0      0.0        0.0   \n",
       "\n",
       "          madrugada  tarde  noche  maniana  XGBRegressor  \\\n",
       "person                                                     \n",
       "0566e9c1          0      1      0        0      0.016541   \n",
       "6ec7ee77          0      0      0        0      0.100654   \n",
       "abe7a2fb          0      0      0        0      0.010634   \n",
       "\n",
       "          RandomForestRegressor  AdaBoostRegressor  \n",
       "person                                              \n",
       "0566e9c1               0.020955           0.116183  \n",
       "6ec7ee77               0.078044           0.293405  \n",
       "abe7a2fb               0.025350           0.165819  \n",
       "\n",
       "[3 rows x 109 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_meta.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictor Stacking\n",
    "\n",
    "Ahora vamos a entrenar un nuevo modelo utilizando como features las predicciones anteriores (metafeatures). También podemos agregar algunos de los features originales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esto realizamos un Random Search. TODO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'learning_rate': 0.3,\n",
    "    'gamma': 1.6317896840572566,\n",
    "    'max_depth': 2,\n",
    "    'objective': 'reg:logistic',\n",
    "    'n_estimators': 25\n",
    "}\n",
    "\n",
    "stacking = XGBRegressor(**param)\n",
    "stack_train = train_meta[[predictor.__class__.__name__ for predictor in base_predictors]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.875543 (+/- 0.022174)\n",
      "CPU times: user 1.52 s, sys: 4 ms, total: 1.53 s\n",
      "Wall time: 1.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = cross_val_score(stacking, stack_train, train_target, cv=10, scoring='roc_auc')\n",
    "print(\"Accuracy: %0.6f (+/- %0.6f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=1.6317896840572566, learning_rate=0.3,\n",
       "       max_delta_step=0, max_depth=2, min_child_weight=1, missing=None,\n",
       "       n_estimators=25, n_jobs=1, nthread=None, objective='reg:logistic',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking.fit(stack_train, train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Optimization\n",
    "\n",
    "Búsque de hiperparámetros para el stacking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbounds = {\n",
    "    'max_depth': (2, 20),\n",
    "    'eta': (0, 0.3),\n",
    "    'gamma': (0, 10),\n",
    "#     'min_child_weight': (1, 5),\n",
    "#     'max_delta_step': (1, 5),\n",
    "#     'subsample': (0, 1),\n",
    "#     'colsample_bytree': (0, 1),\n",
    "#     'colsample_bylevel': (0, 1),\n",
    "#     'lambda': (1, 3),\n",
    "#     'alpha': (0, 2)\n",
    "}\n",
    "\n",
    "discrete = ['max_depth'] # parámetros discretos\n",
    "cv_splits = 10 # cantidad de splits en el cv\n",
    "num_round = 100 # cantidad máxima de boosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(stack_train, label=train_target)\n",
    "def cv_score_xgb(**param):\n",
    "    param['silent'] = 1\n",
    "    param['objective'] = 'reg:logistic'\n",
    "    \n",
    "    # transformo los valores que deben ser discretos\n",
    "    for d in discrete:\n",
    "        param[d] = int(param[d])\n",
    "    \n",
    "    # hago el cv\n",
    "    scores = xgb.cv(param, dtrain, nfold=cv_splits, metrics='auc', verbose_eval=False, shuffle=False, stratified=False, num_boost_round=num_round)\n",
    "    return scores['test-auc-mean'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |    eta    |   gamma   | max_depth |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8753  \u001b[0m | \u001b[0m 0.06027 \u001b[0m | \u001b[0m 8.548   \u001b[0m | \u001b[0m 16.0    \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.8755  \u001b[0m | \u001b[95m 0.2056  \u001b[0m | \u001b[95m 6.063   \u001b[0m | \u001b[95m 4.159   \u001b[0m |\n",
      "=============================================================\n",
      "CPU times: user 38.6 s, sys: 172 ms, total: 38.8 s\n",
      "Wall time: 38.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "optimizer = BayesianOptimization(f=cv_score_xgb, pbounds=pbounds)\n",
    "optimizer.probe(\n",
    "    params = {'eta': 0.06027, 'gamma': 8.548, 'max_depth': 16}\n",
    ")\n",
    "optimizer.maximize(\n",
    "    init_points=0,\n",
    "    n_iter=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': {'eta': 0.20560106670266734,\n",
       "  'gamma': 6.063466743530106,\n",
       "  'max_depth': 4.158627203617048},\n",
       " 'target': 0.8754747}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escribo el mejor resultado en un archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_data = {\n",
    "    'algorithm': 'stacking',\n",
    "    'hyperparameters': optimizer.max['params'],\n",
    "    'cv_splits': cv_splits,\n",
    "    'auc': optimizer.max['target'],\n",
    "    'features': train.columns\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i write_hyperparameters.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción del set testing con los modelos base\n",
    "\n",
    "Utilizamos los modelos entrenados con el 100% del set de entrenamiento para predecir el set de testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = labels_to_predict.merge(df_features, how='inner', on='person')\n",
    "assert(testing.shape[0] == labels_to_predict.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_with_base_predictions = testing.copy()\n",
    "for predictor in base_predictors:\n",
    "    testing_with_base_predictions[predictor.__class__.__name__] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 29s, sys: 24 ms, total: 1min 29s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for predictor in base_predictors:\n",
    "    # como warm_start=False cada vez que llamo fit, el modelo se reinicia\n",
    "    predictor.fit(train, train_target) # train\n",
    "    testing_with_base_predictions[predictor.__class__.__name__] = predictor.predict(testing) # predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción del set testing con el stacking\n",
    "\n",
    "Utilizamos las predicciones como features para que el Stacking las combine en una prediccón final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGBRegressor</th>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4886f805</th>\n",
       "      <td>0.004958</td>\n",
       "      <td>0.002692</td>\n",
       "      <td>0.037771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0297fc1e</th>\n",
       "      <td>0.027957</td>\n",
       "      <td>0.067237</td>\n",
       "      <td>0.158337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2d681dd8</th>\n",
       "      <td>0.009751</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.037771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          XGBRegressor  RandomForestRegressor  AdaBoostRegressor\n",
       "person                                                          \n",
       "4886f805      0.004958               0.002692           0.037771\n",
       "0297fc1e      0.027957               0.067237           0.158337\n",
       "2d681dd8      0.009751               0.003750           0.037771"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_with_base_predictions_for_stacking = testing_with_base_predictions[[predictor.__class__.__name__ for predictor in base_predictors]]\n",
    "testing_with_base_predictions_for_stacking.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = stacking.predict(testing_with_base_predictions_for_stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_target = pd.DataFrame(data=stacking.predict(testing_with_base_predictions_for_stacking))\n",
    "testing_target.index = testing_with_base_predictions_for_stacking.index\n",
    "testing_target.index.name = 'person'\n",
    "testing_target.columns = ['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing_target.to_csv(predicciones_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
